\documentclass{sig-alternate}

\usepackage{bm}
\usepackage{bbm}
\usepackage{amsmath}
\usepackage{alltt, amssymb,stmaryrd}
\usepackage{color}
\usepackage{mdwlist}
\usepackage{float}

\usepackage{algorithm}
\usepackage{algorithmic}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\def\C {\ensuremath{\mathsf{C}}}
\def\M {\ensuremath{\mathsf{M}}}
\def\Q {\ensuremath{\mathbb{Q}}}
\def\N {\ensuremath{\mathbb{N}}}
\def\R {\ensuremath{\mathbb{R}}}
\def\Z {\ensuremath{\mathbb{Z}}}
\def\F {\ensuremath{\mathbb{F}}}
\def\H {\ensuremath{\mathbb{H}}}
\def\K {\ensuremath{\mathbb{K}}}
\def\Kbar {\ensuremath{\overline{\mathbb{K}}}}
\def\L {\ensuremath{\mathbb{L}}}
\def\A {\ensuremath{\mathbb{A}}}
\def\B {\ensuremath{\mathbb{B}}}

\def\va {\ensuremath{\mathsf{a}}}
\def\vy {\ensuremath{\mathsf{a}}}
\def\vu {\ensuremath{\mathsf{u}}}
\def\vb {\ensuremath{\mathsf{b}}}
\def\vc {\ensuremath{\mathsf{c}}}

\def\mul {\ensuremath{\mathrm{mul}}}
\def\rem {\ensuremath{\mathrm{rem}}}
\def\cat {\ensuremath{\mathrm{cat}}}
\def\coeff {\ensuremath{\mathrm{coefficient}}}
\def\mulmod {\ensuremath{\mathrm{mulmod}}}
\def\rev {\ensuremath{\mathrm{rev}}}
\def\x {\ensuremath{\mathbf{x}}}
\def\Tr {\ensuremath{\mathrm{Tr}}}
\DeclareBoldMathCommand{\bgamma}{\gamma}
\DeclareBoldMathCommand{\bbeta}{\eta}
\DeclareBoldMathCommand{\bbbeta}{\beta}
\DeclareBoldMathCommand{\blambda}{\lambda}

\newcounter{algo}

\newenvironment{algorithm_noendline}[4]{\small\begin{center}\begin{minipage}{0.48\textwidth}
      \refstepcounter{algo}
      \label{#4}
      \sf
      \rule{\textwidth}{0.2pt}\\
      \makebox[\textwidth][c]{Algorithm~\arabic{algo}:~\textbf{#1}}\\
      \rule[0.5\baselineskip]{\textwidth}{0.2pt}\\

      \vspace{-12pt}

      \parbox{\textwidth}{\textbf{Input} #2}
      \parbox{\textwidth}{\textbf{Output} #3}

\vspace{-7pt}

      \begin{enumerate*}}{\end{enumerate*}
      \vspace{-11pt}
\end{minipage}\end{center}
}

\newenvironment{algorithm_endline}[4]{\small\begin{center}\begin{minipage}{0.48\textwidth}
      \refstepcounter{algo}
      \label{#4}
      \sf
      \rule{\textwidth}{0.2pt}\\
      \makebox[\textwidth][c]{Algorithm~\arabic{algo}:~\textbf{#1}}\\
      \rule[0.5\baselineskip]{\textwidth}{0.2pt}\\

      \vspace{-12pt}

      \parbox{\textwidth}{\textbf{Input} #2}
      \parbox{\textwidth}{\textbf{Output} #3}

\vspace{-7pt}

      \begin{enumerate*}}{\end{enumerate*}
      \vspace{-11pt}
      \rule{\textwidth}{0.2pt}
\end{minipage}\end{center}
%\vspace{-0.5cm}
}

\floatstyle{plain}
\newfloat{algofloat}{thp}{bla}
\floatname{algofloat}{}

\newcommand{\wrt}{\vdash} 
\newcommand{\ang}[1]{\langle#1\rangle}
\newcommand{\dual}[1]{\overline{#1}}
\newcommand{\todo}[1]{\textcolor{red}{TODO: #1}}

\def\gathen#1{{#1}}
\def\hoeven#1{{#1}}

\newtheorem{Def}{Definition}
\newtheorem{Theo}{Theorem}
\newtheorem{Prop}{Proposition}
\newtheorem{Lemma}{Lemma}

\numberofauthors{3}
\author{
  \alignauthor Luca De Feo\\
  \affaddr{Laboratoire PRiSM}\\
  \affaddr{Universit\'e de Versailles}\\
  \email{luca.de-feo@uvsq.fr}
  \alignauthor Javad Doliskani\\
  \affaddr{Computer Science Department}\\
  \affaddr{Western University}\\
  \email{jdoliska@uwo.ca}
  \alignauthor \'Eric Schost\\
  \affaddr{Computer Science Department}\\
  \affaddr{Western University}\\
  \email{eschost@uwo.ca}
}

\title{Fast arithmetic for the algebraic closure of finite fields}

\begin{document}

\maketitle
\begin{abstract}
  We present algorithms to construct and do arithmetic operations in
  the algebraic closure of the finite field $\mathbb{F}_p$. Our
  approach is inspired by algorithms for constructing irreducible
  polynomials, which first reduce to prime power degrees, then use
  composita techniques. We use similar ideas to give efficient
  algorithms for embeddings and isomorphisms.
\end{abstract}

\category{F.2.1}{Theory of computation}{Analysis of algorithms and problem complexity}[Computations in finite fields]
\category{G.4}{Mathematics of computing}{Mathematical software}
\terms{Algorithms,Theory}
\keywords{Finite fields, irreducible polynomials, extensions.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

Several computer algebra systems or libraries, such as Magma, Sage,
NTL or Flint, offer built-in features to build and compute in
arbitrary finite fields. At the core of these designs, one finds
algorithms for building irreducible polynomials, together with
algorithms to compute embeddings and isomorphisms. The
paper~\cite{bosma+cannon+steel97} describes the system used in Magma,
one of the most complete we are aware of.

Previous algorithms typically rely on linear algebra techniques, for
instance to describe embeddings or isomorphisms (this is the case for
the algorithms in~\cite{bosma+cannon+steel97}, but also for those
in~\cite{LenstraJr91,Allombert02}). Unfortunately, linear algebra
techniques have cost at least quadratic in the degree of the
extensions we consider, and (usually) quadratic memory requirements.
Our goal here is to replace linear algebra by polynomial arithmetic,
exploiting fast polynomial multiplication to obtain algorithms of
quasi-linear complexity. As we will see, we meet this goal for
several, but not all, operations.

\paragraph*{{\bf \rm Setup}}
Let $p$ be a prime (that will be fixed throughout this paper). We are
interested in describing extensions $\F_{p^n}$ of $\F_p$; such an
extension has dimension $n$ over $\F_p$, so representing an element in
it involves $n$ base field elements.

It is customary to use polynomial arithmetic to describe these
extensions (but not necessary: Lenstra's algorithm~\cite{LenstraJr91}
uses an entire multiplication tensor, which has size $n^3$). Given an
extension degree $n$, a first step is then to construct an irreducible
polynomial $Q_n$ of degree $n$ in $\F_p[x]$. This will allow us to
identify $\F_{p^n}$ with $\F_p[x]/\ang{Q_n}$; then, using fast
Euclidean division and extended GCD, operations $(+,\times,\div)$ in
$\F_p[x]/\ang{Q_n}$ all take quasi-linear time in~$n$.

However, this is not sufficient, as we also want mechanisms to perform
(for instance) field embeddings. Given irreducible polynomials $Q_n$
and $Q_m$ over $\F_p$, with $\deg(Q_n)=n$ dividing $\deg(Q_m)=m$,
there certainly exist algorithms that determine an embedding
$\F_p[x]/\ang{Q_n} \to \F_p[x]/\ang{Q_m}$. However, as said above,
most such algorithms use linear algebra techniques. In addition, in
order for the system to be consistent, we must ensure that these
embeddings are {\em compatible}, as explained
in~\cite{bosma+cannon+steel97}.

To bypass these issues, we use an approach inspired by e.g. Shoup's
algorithm for computing irreducible polynomials~\cite{Shoup90,shoup94}
(see also~\cite{couveignes+lercier11,lenstra+desmit08-stdmodels}):
first reduce to the case of prime power degrees, then use composita
techniques, in a manner that ensures compatibility of the embeddings
automatically.

\smallskip\noindent{{\bf \rm Background: towers.}}
Suppose that for any prime $\ell$, an {\em $\ell$-adic tower} over
$\F_p$ is available. By this, we mean a family of polynomials
$(T_{\ell,i})_{i \ge 1}$, with $T_{\ell,i} \in \F_p[x_1,\dots,x_i]$,
monic of degree $\ell$ in $x_i$, such that the ideal
$\ang{T_{\ell,1},\dots,T_{\ell,i}}$ is prime in $\F_p[x_1,\dots,x_i]$.
Of course, our model of the field with $p^{\ell^n}$ elements could
simply be
$\K_{\ell^n}=\F_p[x_1,\dots,x_n]/\ang{T_{\ell,1},\dots,T_{\ell,n}}$,
but we prefer to work with univariate polynomials (the cost of
arithmetic operations is higher in the multivariate basis).  

For $1 \le i \le n$, let then $Q_{\ell^i}$ be the minimal polynomial
of $x_i$ in the extension $\F_p \to \K_{\ell^n}$. This polynomial does
not depend on $n$, but only on $i$; it is monic, irreducible of degree
$\ell^i$ in $\F_p[x_i]$ and allows us to define $\F_{p^{\ell^i}}$ as
$\F_p[x_i]/\ang{Q_{\ell^i}}$.

For $1 \le i \le j \le n$, let further $Q_{\ell^i,\ell^{j-i}}$ be the
minimal polynomial of $x_j$ in the extension
$\F_p[x_i]/\ang{Q_{\ell^i}} \to \K_{\ell^n}$ (as above, it does not
depend on $n$). This polynomial is monic, irreducible of degree
$\ell^{j-i}$ in $\F_{p^{\ell^i}}[x_j]=\F_p[x_i]/\ang{Q_{\ell^i}}[x_j]$.

In particular, $\F_p[x_j]/\ang{Q_{\ell^j}}$ and
$\F_p[x_i,x_j]/\ang{Q_{\ell^i},Q_{\ell^i,\ell^{j-i}}}$ are two models
for $\F_{p^{\ell^j}}$. Provided conversions between these two
representations are available, this will allow us to perform
embeddings (that will necessarily be compatible) between different
levels of the ``tower'', that is extensions of degrees $(\ell^i)_{i
  \ge 1}$.

Such towers, together with efficient conversion algorithms, were
constructed in the cases $\ell = p$
in~\cite{cantor89,couveignes00,df+schost12}, $\ell=2$
in~\cite{DoSc12}, and for other values of $\ell$ in~\cite{DeDoSc13}.
Thus, it remains to give algorithms to ``glue'' towers defined for
different values of $\ell$. This is the purpose of this paper.

\smallskip\noindent{{\bf \rm Our contribution.}} The algorithms used
in the constructions of the towers are inspired by those used
in~\cite{Shoup90,shoup94,couveignes+lercier11} to construct
irreducible polynomials. Also used in these references is the
following idea: if $Q_n(x)$ and $Q_m(y)$ are irreducible polynomials
over $\F_p$, with coprime degrees $n$ and $m$, their {\em composed
  product} $Q_{nm} = \prod_{1 \le i \le n, 1 \le j \le m} (z- a_i
b_j)$ is irreducible of degree $mn$ in $\F_p[z]$ ($(a_i)_{1 \le
  i \le n}$ and $(b_j)_{1 \le j \le m}$ are the roots of $Q_n$ and
$Q_m$ in an algebraic closure of $\F_p$).

If the goal is building irreducible polynomials, computing $Q_{nm}$ is
enough; an algorithm given in~\cite{BoFlSaSc06} has quasi-linear cost
in $mn$ (in this paper, we use an {\em algebraic complexity model},
where the cost of an algorithm is counted in terms of the number of
operations $(+,\times,\div)$ in $\F_p$). Our goal here is to give
algorithms for further operations: computing embeddings of the form
$\varphi_x: \F_p[x]/\ang{Q_n}\to \F_p[z]/\ang{Q_{nm}}$ or $\varphi_y:
\F_p[y]/\ang{Q_m}\to \F_p[z]/\ang{Q_{nm}}$, and the isomorphism $\Phi:
\F_p[x,y]/\ang{Q_n,Q_m}\to \F_p[z]/\ang{Q_{nm}}$ or its inverse.

Standard solutions to these questions exist, using {\em modular
  composition} techniques: once the image $S=\varphi_x(x)$ is known,
computing $\varphi_x(a)$ amounts to computing $a(S) \bmod Q_{nm}$.
This can be done using the Brent and Kung algorithm~\cite{brent+kung};
the resulting cost is $O(n m^{(\omega+1)/2}) \subset O(n m^{1.69})$
for $\varphi_x$ and $O((n m)^{(\omega+1)/2}) \subset O(n^{1.69}
m^{1.69})$ for $\Phi$ or its inverse. Here, we denote by $\omega$ a
constant in $(2,3]$ such that one can multiply matrices of size $n$
  over $A$ using $O(n^\omega)$ operations $(+,\times)$ in~$A$; using
  the algorithms of~\cite{coppersmith+winograd,Williams12}, we can
  take $\omega \le 2.38$.


\paragraph*{{\bf \rm Notation}}
We denote by $\M:\N \to \N$ a function such that for any ring $A$,
polynomials in $A[x]$ of degree at most $n$ can be multiplied in
$\M(n)$ operations $(+,\times)$ in $A$, and we make the usual
super-linearity assumptions on $\M$~\cite[Chapter~8]{vzGG}. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Preliminaries}

We recall first previous results concerning basic polynomial
arithmetic and duality.  In all this section, the ground field $k$ is
fixed. For integers $m,n$, we denote by $k[x]_m$
(resp.\ $k[x,y]_{m,n}$) the set of polynomials $P$ in $k[x]$ with
$\deg(P) <m$ (resp.\ $P$ in $k[x,y]$ with $\deg(P,x) <m$ and
$\deg(P,y)<n$).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Polynomial multiplication and remainder}

We start with some classical algorithms and their complexity; for all
the algorithms that follow, all polynomials are written on the
canonical monomial basis (this is innocuous for the moment, but other
bases will be discussed below).

The product of two polynomials of respective degrees at most $m$ and
$n$ can be computed in $\M(\max(m,n))$ operations in $k$.  If $P$ is a
monic polynomial $P$ of degree $m$ in $k[x]$, for $n \ge 1$, we let
$\rem(.,P,n)$ be the operator
$$
\begin{array}{cccc}
\rem(.,P,n): &k[x]_n& \to &k[x]_{m}\\
& a & \mapsto & a \bmod P.
\end{array}$$ 
For $n \le m$, this is free of cost. For $n > m$, this can be computed
in time $O(n\M(m)/m)$ using the Cook-Sieveking-Kung algorithm and
blocking techniques~\cite[Ch.~5.1.3]{Bostan10}. Defining
$A=k[x]/\ang{P}$, and choosing a fixed $b \in A$, we can then define
the mapping $\mulmod(.,b,P)$, which maps $a \in A$ to $ab \bmod P$; it
can be computed in time $O(\M(m))$. 

Finally, for a fixed integer $m$, we denote the reversal operator in
length $m$ by
$$
\begin{array}{cccc}
\rev(.,m): &k[x]_m &\to& k[x]_m  \\
& a & \mapsto & x^{m-1} a(1/x).
\end{array}$$ 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The transposition principle}
\label{sec:algor-dual-basis}

The {\em transposition principle} is an algorithmic result which
states that given an algorithm that performs an $r \times s$
matrix-vector product $u \mapsto M u$, one can deduce an algorithm
with the same cost, up to $O(\max(r,s))$, which performs the
transposed matrix-vector product $v \mapsto M^t
v$~\cite[Ch.~13]{burgisser+clausen-shokrollahi}.

Although that theorem is constructive, the proof involves going down
to the DAG representation of the algorithm, which is hardly
convenient.  In the rest of this article, we will reuse techniques
from~\cite{bostan+lecerf+schost:tellegen} in order to simplify the
transposition process: in a nutshell, most of our algorithms will rely
on a few basic operations (such as polynomial or matrix
multiplication), and their transposes are obtained by transposing each
basic subroutine, and reversing their order.

%% If $M$ represents a $k$-linear mapping $E \to F$, its transpose can
%% naturally be seen as a $k$-linear mapping between the dual spaces $F^*
%% \to E^*$ (other interpretations will be discussed below). We will
%% often work with vector spaces such as $k[x]_m$, represented on the
%% standard polynomial basis $(x^i)_{i<m}$; its dual space $k[x]_m^\ast$
%% is identified with $k^m$.

%% Mutliplication by a fixed $b\in k[x]_m$ is a linear map
%% \begin{equation*}
%%   M_b: k[x]_n \to k[x]_{m+n}
%% \end{equation*}
%% for any positive integer $n$. By definition, its \emph{dual} (or
%% \emph{transpose}, especially when talking about algorithms) is a
%% linear map
%% \begin{equation*}
%%   M_b^t : k^{m+n} \to k^n
%% \end{equation*}
%% such that
%% \begin{equation*}
%%   \ang{\ell,M_b(a)} = \ang{\ell,ab} = \ang{M_b^t(\ell),a}.
%% \end{equation*}

Let us briefly review the transposes of operations described in the
previous subsection. The transpose of polynomial multiplication is
described in~\cite{bostan+lecerf+schost:tellegen}; it is closed
related to the {\em middle product}~\cite{hanrot+quercia+zimmermann}.
Let next $P$ be monic of degree $m$, and define $A=k[x]/\ang{P}$; we
can then discuss the tranposes of $\rem$ and $\mulmod$. As shown
in~\cite{bostan+lecerf+schost:tellegen}, the dual map
$$
\begin{array}{cccc}
\rem^t(.,P,n): &k^m& \to &k^n
\end{array}$$ 
takes as input a linear form $\ell\in A^\ast$ given by the values
$(\ell(x^i))_{0 \le i < m}$; the output is then the values
$(\ell(x^i))_{0 \le i < n}$. For $n < m$, there is nothing to do. For
greater values of $n$, $\rem^t$ is \emph{linear sequence extension}:
it takes as input the initial $m$ values of a linear recurring
sequence of minimal polynomial $P$, and outputs its first $n$ values.
LFSRs give a simple, though suboptimal, implementation of this
operator. The transposed version of the Cook-Sieveking-Kung fast
Euclidean division algorithm yield better algorithms: as for the
forward direction the cost of the transposed algorithm is
$O(n\M(m)/m)$ operations in $k$~\cite{vzgathen+shoup92:journal,shoup99}.

Multiplication by a fixed $b\in A$ is a linear map $M_b:A\to A$. By
definition, the dual map $M_b^t: A^* \to A^*$ maps a linear form to $b
\cdot \ell$, which is such that $(b \cdot \ell)(a)
=\ell(ab)$. Algorithms for $\mulmod^t$ have been subject to much
research (for instance, Berlekamp's \emph{bit serial
  multiplication}~\cite{Berlekamp82} is a popular arithmetic circuit
for $\mulmod^t$ in the case $k=\F_2$); algorithms of cost $O(\M(m))$
are given in~\cite{shoup99,bostan+lecerf+schost:tellegen}. Finally,
the reversal operator on $k[x]_m$ is its transpose.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Trace and duality}

We discuss some classical facts about duality induced by
non-degenerate bilinear forms, pairs of primal / dual bases, and give
change-of-basis algorithms for a useful particular case. In all this
section, $k$ is a perfect field.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Duality}\label{ssec:duality}

A general reference for what follows
is~\cite[Ch.~IX.1.8]{BourbakiAlgCom9}. Let $E$ and $F$ be $k$-vector
spaces, with $\dim(E)=\dim(F) < \infty$; suppose further that
$\ang{.,.}: E\times F \to k$ is a non-degenerate $k$-bilinear form
Then, to any $k$-vector space basis $\bgamma=(\gamma_i)_i$ of $E$, we
can associate a unique \emph{dual basis}
$\bgamma^\ast=(\gamma_i^\ast)_i$ of $F$ such that $
\ang{\gamma_i,\gamma^\ast_j} = \delta_{i,j}$ (the Kronecker symbol).

In other words, given $a$ in $F$, the coefficients $(a_i)$ of $a$ on
the basis $\bgamma^\ast$ are given by $a_i=\ang{\gamma_i, a}$. A
standard example (implicitly used in the previous section) is the case
where $F$ is the dual $E^*$ of $E$, with $\ang{v,\ell}=\ell(v)$ for
all $v\in E$ and $\ell \in E^*$; we will see in the next subsection
another family of examples, with $E=F$.

Let $E',F'$ be two further vector spaces, with $\dim(E')=\dim(F')$ and
let $\ang{.,.}$ be a $k$-bilinear form $E'\times F' \to k$. Then, to
any $k$-linear mapping $u:E\to E'$, one associates its {\em dual}
(with respect to $\ang{.,.}$ and $\ang{.,.}'$), which is a $k$-linear
mapping $u^t: F' \to F$ characterized by the equality
$\ang{u(a),b'}'=\ang{a,u^t(b')}$, for all $a\in E$ and $b'$ in $F'$.

Let as above $\bgamma$ be a basis of $E$, and let $\bgamma^\ast$ be
the dual basis of $F$; consider as well a basis $\bbeta$ of $E'$ and
its dual basis $\bbeta^\ast$ of $F'$. If $M$ is the matrix of $u$ in
the bases $(\bgamma,\bbeta)$, the matrix of $u^t$ in the bases
$(\bbeta^\ast,\bgamma^\ast)$ is the transpose of $M$. The
transposition principle then implies that, from an algorithm that
computes $u: E \to E'$ in the bases $(\bgamma,\bbeta)$, we deduce the
existence of an algorithm for the dual map $u^t: F' \to F$ in the
bases $(\bbeta^\ast,\bgamma^\ast)$, with essentially the same cost.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Traces in reduced algebras}

General reference for the following
are~\cite{Kunz86,Cox-Little-OShea:UAG2005}. Suppose now that $s$ a
positive integer, and $I$ a zero dimensional radical ideal in
$k[x_1,\dots,x_s]$; thus, $A=k[x_1,\dots,x_s]/I$ is a reduced
$k$-algebra of finite dimension $d$, where $d$ is the cardinality of
$V=V(I) \subset\overline{k}^s$ (but in general, $A$ is not a field).

Let $a$ be in $A$. As we did in the case of one variable, we associate
to $a$ the endomorphism of multiplication-by-$a$ $M_a: A \to A$ given
by $M_a(b)=ab$.  Even though $A$ may not be a field, we may still
define the {\em minimal polynomial} of $a$ as the minimal polynomial
of $M_a$; since $I$ is radical, this polynomial is squarefree, with
roots $a(x)$, for $x$ in $V$. Similarly, we define the \emph{trace} of
$a$ as the trace of $M_a$, and denote it by $\tau_I(a)$. Thanks to $I$
being radical, the trace defines a non-degenerate bilinear form on
$A\times A$, given by $\ang{a,b}_I = \tau_I(ab)$.

Thus, to any basis $\bgamma=(\gamma_i)_{0 \le i < d}$ of $A$, one can
associate a dual basis $\bgamma^\ast=(\gamma^\ast_i)_{0 \le i < d}$,
such that $\ang{\gamma_i, \gamma^\ast_j}_I=\delta_{i,j}$ for all
$i,j$.  It will be useful to keep in mind that for $a \in A$, its
expression on the dual basis $\bgamma^\ast$ is $a=\sum_{0 \le i < d}
\ang{a,\gamma_i}_I \gamma^\ast_i$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Conversion algorithms} \label{ssec:conversions}
\label{sec:trace-formulas}

We now describe algorithms for converting between the monomial and its
dual, in two particular cases, involving respectively of univariate
and bivariate polynomials. In both cases, our conclusion will be that
such conversions have quasi-linear complexity.

\smallskip\noindent{{\bf \rm Univariate conversion.}} 
Let $P$ be monic of degree $m$ and squarefree in $k[x]$, and define
$A=k[x]/\ang{P}$. We denote by $\tau_P$ the trace modulo $P$.

The $k$-algebra $A$ is endowed with the canonical monomial basis
$\bgamma=(x^i)_{0 \le i < m}$.  In this case, conversion algorithms
between the monomial basis and its dual $\bgamma^\ast$ are essentially
well-known (though usually not stated in these terms). Indeed, in view
of what was said in the previous subsection, the coefficients of an
element $a \in A$ on the dual basis are the traces $\tau_P(ax^i)_{0
  \le i < m}$.  The following lemma shows that the generating series
of these traces is rational, with a known denominator; this will be
the key to the conversion algorithm. This is a restatement of
well-known results, see for instance the proof
of~\cite[Theorem~3.1]{rouiller99}.

\begin{Lemma}\label{lemma:trace:1}
  For $a=\sum_{0 \le i < m} a_i x^i$ in $A$, the following equality
  holds in $k[[x]]$:
  $$\sum_{i \ge 0} \tau_P(a x^i) x^i = \frac{\rev( P' a \bmod P,m)}{\rev(P,m+1)}.$$
\end{Lemma}

The conversion algorithms follow easily. In these algorithms, and all
that follows, input and outputs are vectors (written in {\sf sans
  serif} font).

\begin{algorithm_noendline}
{MonomialtoDual$(\va,P)$}
{$\va=(a_i)_{0 \le i < m} \in k^m$ \\  $P$ monic squarefree in $k[x]$ of degree $m$}
{$(\tau_P(a x^i))_{0 \le i < m}$, with $a=\sum_{0 \le i < m} a_i x^i$}
{algo:minpolytotrace}
\item $T = 1/\rev(P, m+1) \bmod x^m$
\item $b = \rev(P' \sum_{0 \le i < m} a_i x^i \bmod P, m)\, T \bmod x^m$
\item {\bf return} $(\coeff(b,x^i))_{0 \le i < m}$
\end{algorithm_noendline}

\begin{algorithm_endline}
{DualToMonomial$(\vb, P)$}
{$\vb=(b_i)_{0 \le i < m} \in k^m$\\ $P$ monic squarefree in $k[x]$ of degree $m$}
{$(a_i)_{0 \le i < m}$ such that $\tau_P(\sum_{0 \le i < m} a_i x^{i+j}) = b_j$}
{algo:tracetopoly}
\item $S = 1/P' \bmod P$
\item $b= \rev(P,m+1) \sum_{0 \le i < m} b_i x^i \bmod x^m$
\item $c= \rev(b, m)$
\item $d =c\, S \bmod P$
\item {\bf return} $(\coeff(d,x^i))_{0 \le i < m}$
\end{algorithm_endline}

\begin{Lemma}\label{lemma:uniconv}
  Algorithms~\ref{algo:minpolytotrace} and~\ref{algo:tracetopoly} are
  correct. The former uses $O(\M(m))$ operations in $k$, and the
  latter $O(\M(m)\log(m))$.  If the polynomial $S=1/P' \bmod P$ is
  known, the running time of Algorithm~\ref{algo:tracetopoly} drops to
  $O(\M(m))$.
\end{Lemma}
\begin{proof}
  Correctness follows from Lemma~\ref{lemma:trace:1}.  Once we point
  out that power series inversion modulo $x^m$ can be done in time
  $O(\M(m))$, the running time analysis of the former is
  straightforward. For Algorithm~\ref{algo:tracetopoly}, the dominant
  part is the computation of $S$, which takes time $O(\M(m)\log(m))$
  by fast XGCD; all other steps take $O(\M(m))$ operations in $k$.
\end{proof}

\noindent{{\bf \rm Bivariate conversions.}} Let now $P,Q$ be monic of
respective degrees $m$ and $n$ and squarefree in respectively $k[x]$
and $k[y]$, and define $A=k[x,y]/I$, with $I=\ang{P,Q}$. Remark that
$A$ has the canonical monomial basis $(x^i y^j)_{0 \le i <m, 0 \le j <
  n}$. For $a$ in $k[x,y]$, $a \bmod I$ denotes the polynomial in
$k[x,y]_{m,n}$ obtained by reduction modulo both $P$ and $Q$.  We
denote by $\tau_I$ the trace modulo $I$, and by $\tau_P$ and $\tau_Q$
the traces modulo respectively $\ang{P}$ and $\ang{Q}$.

In addition to its monomial basis, $A$ can be endowed with a total of
four natural bases, which are described as follows. Let
$\bgamma=(x^i)_{0 \le i < m}$ and $\bbeta=(y^i)_{0 \le j < n}$ be the
monomial bases of respectively $k[x]/\ang{P}$ and $k[y]/\ang{Q}$; let
$\bgamma^\ast$ and $\bbeta^\ast$ be their respective dual bases, with
respect to $\tau_P$ and $\tau_Q$. The monomial basis seen above is
$\bgamma \otimes \bbeta$; the other combinations $\bgamma^\ast \otimes
\bbeta$, $\bgamma \otimes \bbeta^\ast$ and $\bgamma^\ast \otimes
\bbeta^\ast$ are bases of $A$ as well. The following easy lemma will
help us exhibit the duality relationships between them; it follows
from the fact that $A$ is the tensor product of $k[x]/\ang{P}$ and
$k[y]/\ang{Q}$.

\begin{Lemma}
  \label{lemma:traces:PQR1}
  Let $b$ be in $k[x]/\ang{P}$ and $c$ in $k[y]/\ang{Q}$. Then we have
  $\tau_I(bc) = \tau_P(b) \ \tau_Q(c)$.
\end{Lemma}

This lemma implies that $\bgamma \otimes \bbeta$ and $\bgamma^\ast
\otimes \bbeta^\ast$ are dual to one another with respect to
$\ang{.,.}_I$, as are $\bgamma^\ast \otimes \bbeta$ and $\bgamma
\otimes \bbeta^\ast$. After a precomputation of cost $O(\M(m)\log(m) +
\M(n)\log(n))$, Lemma~\ref{lemma:uniconv} shows that conversions
between any pair of these dual bases can be done using
$O(n\M(m)+m\M(n))$ operations in $k$ (by applying the univariate
conversion algorithms $n$ times $x$-wise and $m$ times $y$-wise). Using
fast multiplication, this quasi-linear in the dimension $mn$ of $A$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Embedding and isomorphism} \label{sec:emb-iso}

This section contains the main algorithms of this paper. We consider
two squarefree polynomials $P(x)$ and $Q(y)$ of respective degrees $m$
and $n$, with coefficients in a perfect field $k$. Let us then set
$A=k[x,y]/I$, where $I$ is the ideal $\ang{P(x),Q(y)}$ in $k[x,y]$. In
all this section, {\em we assume that $xy$ is a generator of $A$ as a
  $k$-algebra}. 

The main example we have in mind is the following: $k$ is a finite
field and both $P$ and $Q$ are irreducible, with $\gcd(m,n)=1$; then
our assumption is satisfied and in addition $A$ is a field, namely,
the {\em compositum} of the fields $k[x]/\ang{P}$ and $k[y]/\ang{Q}$,
see~\cite{BrCa87}. More generally, if we let $(r_i)_{i<m}$ be the
roots of $P$ in an algebraic closure of $k$, and let $(s_j)_{j<n}$ be
the roots of $Q$, then as soon as the products $r_i s_j$ are pairwise
distinct, $xy$ generates $A$ as a $k$-algebra.

Let $R \in k[z]$ be the minimal polynomial of $xy$ in the extension
$A/k$ (equivalently, the roots of $R$ are the products $r_i s_j$);
this polynomial is known as the {\em composed product} of $P$ and $Q$,
and we will denote it $R = P \odot Q$. As $k$-algebras, we have $A
\simeq k[x]/\ang{R}$, so there exist embeddings of the form
$$
\begin{array}{ccccc}
&\varphi_x: & k[x]/\ang{P} & \to & k[z]/\ang{R}\\
& & x & \mapsto & S,\\[2mm]
\text{and} & \varphi_y: & k[y]/\langle Q \rangle & \to & k[z]/\ang{R}\\
& & y & \mapsto & T,
\end{array}
$$
for some polynomials $S$ and $T$ in $k[z]$ of degrees less
than $mn$. We also have an isomorphism of the form
$$\begin{array}{cccc} 
\Phi:&  A=k[x,y]/\langle P,Q\rangle & \to & k[z]/\ang{R} \\
&  x & \mapsto & S \\
&  y & \mapsto & T \\
&  xy & \mapsfrom & z.
\end{array}$$
In this section, we give algorithms for computing $R$, applying
$\varphi_x$ and $\varphi_y$ as well as their inverses (when
well-defined), as well as $\Phi$ and its inverse. Except from the
computation of $R$, these are all linear algebra problems.

If $R,S,T$ are known, then a direct solution is available: modular
composition. For instance assuming $S=\varphi_x(x)$ is known,
$\varphi_x(a)$ is computed as $b=a(S) \bmod R$. Using Brent and Kung's
modular composition techniques~\cite{brent+kung}, this can be done in
$O(n m^{(\omega+1)/2})$ operations in $k$, since we evaluate a
polynomial of degree $m$ modulo the polynomial $R$ of degree $mn$ (see
the analysis in~\cite{shoup94}). Similarly, once $S$ and $T$ are
known, computing $\Phi(a)$ for $a$ in $A$ can be done using a
bivariate version of the Brent-Kung algorithm, with running time
$O((nm)^{(\omega+1)/2})$~\cite{PoSc13b}.

We take a different path. Our algorithms have quasi-linear running
time for $\varphi_x$ and $\varphi_y$ and improve on the Brent-Kung
algorithm for $\Phi$; put together, they establish
Theorem~\ref{theo:main}. One of the key aspects of these algorithms is
that some are written in the usual monomial bases, whereas others are
naturally expressed in the corresponding dual bases. From the
complexity point of view, this is not an issue, since we saw that all
change-of-bases can be done in quasi-linear time.

In what follows, we write $\tau_P,\tau_Q,\tau_R,\tau_I$ for the traces
modulo the ideals $\ang{P}\subset k[x]$, $\ang{Q} \subset k[y]$,
$\ang{R} \subset k[z]$ and $I=\ang{P,Q} \subset k[x,y]$; the
corresponding bilinear forms are denoted by $\ang{.,.}_P$, \dots

We will denote by $\bgamma=(x^i)_{0 \le i < m}$, $\bbeta=(y^i)_{0 \le
  j < n}$ and $\bbbeta = (z^i)_{0 \le i < mn}$ the monomial bases of
respectively $k[x]/\ang{P}$, $k[y]/\ang{Q}$ and $k[z]/\ang{R}$. We let
$\bgamma^\ast=(\gamma^\ast_i)_{0 \le i <m}$,
$\bbeta^\ast=(\eta^\ast_i)_{0 \le i < n}$ and
$\bbbeta^\ast=(\beta^\ast_i)_{0 \le i < mn}$ be the dual bases, with
respect to respectively $\ang{.,.}_P$, $\ang{.,.}_Q$ and
$\ang{.,.}_R$.

Finally, we denote by $\vu_P \in k^m$ the vector of the coordinates of
$1 \in k[x]/\ang{P}$ on the dual basis $\bgamma^\ast$; the vector
$\vu_Q$ is defined similarly. These vectors can both be computed in
quasi-linear time, since we have, for instance, $\vu_P = {\rm
  MonomialToDual}((1,0,\dots,0), P)$. Thus, in what follows, we assume
that these vectors are known.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Embedding and computing $R$} 

We first show how to compute the embeddings $\varphi_x$ and
$\varphi_y$, and their inverses in quasi-linear time in $mn$. We
actually give a slightly more general algorithm, which computes the
restriction of $\Phi$ to the set $$\Pi= \{bc \,\mid\, b\in
k[x]/\ang{P},\ c\in k[y]/\ang{Q}\} \subset A=k[x,y]/\ang{P,Q}.$$ We
will use the following lemma, which results from the base independence
of the trace (the second equality is Lemma~\ref{lemma:traces:PQR1}).
\begin{Lemma}
  \label{lemma:traces:PQR}
  Let $b$ be in $k[x]/\ang{P}$ and $c$ in $k[y]/\ang{Q}$. Then we have
  $\tau_R(\Phi(bc)) = \tau_I(bc) = \tau_P(b) \ \tau_Q(c)$.
\end{Lemma}
An easy consequence is that $\tau_R(z^i) =
\tau_P(x^i)\tau_Q(y^i)$. From this, we immediately deduce
Algorithm~\ref{algo:embed}, which computes the image in $k[z]/\ang{R}$
of any element of $\Pi$, with inputs and outputs written on dual
bases.


\vspace{-5pt}

\begin{algorithm_endline}
{Embed$(\vb,\vc,\ell)$}
{$\vb=(b_i)_{0 \le i < m} \in k^m$, $\vc=(c_i)_{0 \le i < n} \in k^n$\\
    an optional integer $\ell \ge mn$ set to $\ell=mn$ by default}
{$\va=(a_i)_{0 \le i < \ell} \in k^{\ell}$}
{algo:embed}
\item $(t_i)_{0\le i<\ell} = \rem^t(\vb,P,\ell)$
\item $(u_i)_{0\le i<\ell} = \rem^t(\vc,Q,\ell)$
\item {\bf return}$(t_i u_i)_{0 \le i <\ell}$
\end{algorithm_endline}

\begin{Lemma}\label{lemma:algo:embed}
  Let $b \in k[x]/\ang{P}$ and $c \in k[y]/\ang{Q}$.  Given the
  coefficients $\vb$ and $\vc$ of respectively $b$ and $c$ in the
  bases $\bgamma^\ast$ and $\bbeta^\ast$, {\em Embed}$(\vb,\vc,\ell)$
  computes $a_i=\tau_R(\Phi(bc)z^i$ for $0 \le i < \ell$ in time
  $O(\ell(\M(m)/m+\M(n)/n))$. If $\ell=mn$, $(a_i)_{0 \le i < mn}$ are
  the coefficients of $\Phi(bc)$ in the basis~$\bbbeta^\ast$.
\end{Lemma}
\begin{proof}
  Recall that for $0 \le i <m$, $b_i = \tau_P(bx^i)$, and that for $0
  \le i < n$, $c_i = \tau_Q(cy^i)$. By definition of $\rem^t$, the
  sequences $(t_i)$ and $(u_i)$ encode the same traces, but up to
  index $\ell$.  By Lemma~\ref{lemma:traces:PQR}, the algorithm
  computes
  \begin{eqnarray*}
    \bigl(\tau_P(bx^i)\tau_Q(cy^i)\bigr)_{i<\ell} &=&  \bigl(\tau_R(\Phi(bc x^i y^i))\bigr)_{i<\ell}\\
    &=&  \bigl(\tau_R(\Phi(bc) z^i))\bigr)_{i<\ell},
  \end{eqnarray*}
  as claimed; for $\ell=mn$, this is exactly the representation of
  $\Phi(bc)$ on the dual basis $\bbbeta^\ast$ of $k[z]/\ang{R}$. The
  cost of the two calls to $\rem^t$ is given in
  Section~\ref{sec:algor-dual-basis}; the last step takes $\ell$
  multiplications in $k$.
\end{proof}

In particular, the map $\varphi_x$ is computed as
Embed$(\cdot,\vu_Q)$, and the map $\varphi_y$ as
Embed$(\vu_P,\cdot)$. Another interesting consequence is that, when
$A$ is known to be a field, Embed allows us to compute $R$, using the
Berlekamp-Massey algorithm.

\begin{algorithm_endline}
{Compute$R(P,Q)$}
{$P$ in $k[x]$, $Q$ in $k[y]$}
{$R$ in $k[z]$}
{algo:R}
\item $(t_i)_{0 \le i < 2mn}={\rm Embed}(\vu_P,\vu_Q,2mn)$,
\item {\bf return} BerlekampMassey$((t_i)_{0 \le i < 2mn})$
\end{algorithm_endline}

Indeed, in this case, Embed$(\vu_P,\vu_Q,2mn)$ computes the sequence
$(\tau_R(z^i))_{0\le i < 2mn}$. If we know that $A$ is a field, $R$ is
irreducible, so the minimal polynomial of this sequence (which is
computed by the Berlekamp-Massey algorithm) is precisely $R$; the
running time is $O(\M(mn)\log(mn))$ operations in $k$. This algorithm
for computing $R$ is well-known; see for instance~\cite{BoFlSaSc06}
for a variant using power series exponentials instead of
Berlekamp-Massey's algorithm (that applies in large enough
characteristic) and~\cite{BGPS05} for the specific case of finite
fields of small characteristic.


For the inverse of $\varphi_x$, we take $a$ in $k[z]/\langle R
\rangle$ of the form $a=\varphi_x(b)$, and compute $b$. Using the
equality of Lemma~\ref{lemma:traces:PQR} in the form $\tau_P(b x^i)
=\tau_R(a z^i)/\tau_Q(y^i)$ would lead to a simple algorithm, but some
traces $\tau_Q(y^i)$ may vanish. 

We take a different path. Let $c$ be a fixed element in $k[y]/\ang{Q}$
such that $\tau_Q(c)=1$; we will take $c$ the first element
$\eta^\ast_0$ of the dual basis of $k[y]/\ang{Q}$, but this is not
necessary. Let us denote by $\epsilon: k[x]/\ang{P} \to k[z]/\ang{R}$
the mapping defined by $\epsilon(b) = \Phi(b c)$, and let $\epsilon^t:
k[z]/\ang{R} \to k[x]/\ang{P}$ be its dual map with respect to the
bilinear forms $\ang{.,.}_R$ and $\ang{.,.}_P$. Then, for $b$ and $b'$
in $k[x]/\ang{P}$, we have
\begin{eqnarray*}
\ang{b,b'}_P = \tau_P(b b') &=&  \tau_P(b b')\tau_Q(c) \\
&=& \tau_R( \Phi(b b' c))\\
&=& \ang{\epsilon(b), \Phi(b')}_R \\
&=& \ang{b, \epsilon^t(\Phi(b'))}_P,
\end{eqnarray*}
where the third equality comes from
Lemma~\ref{lemma:traces:PQR}. Using the non-degeneracy of
$\ang{.,.}_P$, we get $\epsilon^t(\Phi(b')) = b'$, that is,
$\epsilon^t(\varphi_x(b')) = b'$. Thus, $\epsilon^t$ is an inverse of
$\varphi_x$ on its image.

Writing $\vc=(1,0,\dots,0)$, we remark that Embed$(.,\vc)$ precisely
computes the mapping $b\mapsto \epsilon(b)$. Since Embed is written in
the dual bases, the discussion of Section~\ref{ssec:duality} shows
that transposing this algorithm (with respect to $b$) yields an
algorithm for $\epsilon^t$ written in the monomial bases. 

\vspace{-5pt}

\begin{algorithm_endline}
{Project$(\va)$}
{$\va=(a_i)_{0 \le i < mn} \in k^{mn}$}
{$\vb=(b_i)_{0 \le i < m} \in k^m$}
{algo:inverseEmbed}
\item $\vc=(1,0,\dots,0)$ 
\item  $(u_i)_{0\le i<mn} = \rem^t(\vc,Q,mn)$
\item \label{algo:inverseEmbed:dotprod} $d = \sum_{i=0}^{mn-1} a_i u_i x^i  \bmod P$
\item {\bf return} \label{algo:inverseEmbed:mod} $(\coeff(d,i))_{0 \le i < m}$
\end{algorithm_endline}

\begin{Lemma}\label{lemma:project}
  Let $b \in k[x]/\ang{P}$ and $a=\varphi_x(b)$. Given the
  coefficients $\va$ of $a$ in the basis $\bbbeta=(z^i)_{0 \le i
    < mn}$, {\em Project}$(\va)$ computes the coefficients of $b$ in
  the basis $\bgamma=(x^i)_{0 \le i < m}$ using $O(n\M(m) + n\M(n))$
  operations in $k$.
\end{Lemma}
\begin{proof}
  We show correctness using transposition techniques as
  in~\cite{bostan+lecerf+schost:tellegen}. For fixed $\vc$,
  Embed$(\vb,\vc)$ is linear in $\vb$ and can be written as
  $\pi_\vc\circ\rem^t$, where $\pi_\vc$ is the map that multiplies a
  vector in $k^{mn}$ coefficient-wise by $(\tau_Q(c y^i))_{i<mn}$, for
  $c=\sum_{0 \le i < n} c_i \eta^\ast_i$.  Hence, its transpose is
  $\rem\circ\pi_\vc^t$. It is evident that $\pi_\vc^t=\pi_\vc$ (since
  $\pi_\vc$ is a diagonal map), whereas $\rem$ is just reduction
  modulo $P$. These correspond to
  steps~\ref{algo:inverseEmbed:dotprod}
  and~\ref{algo:inverseEmbed:mod}. The discussion above now proves
  that the output is $\epsilon^t(a)$. The cost analysis is similar to
  the one in Lemma~\ref{lemma:algo:embed}.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Isomorphism} 

We are not able to give an algorithm for $\Phi$ that would be as
efficient as those for embedding; instead, we provide two algorithms,
with different domains of applicability. In what follows, without
loss of generality, {\em we assume that $m\le n$}.

Recall that $\bgamma \otimes \bbeta$,\ $\bgamma^\ast \otimes
\bbeta$,\ $\bgamma \otimes \bbeta^\ast$ and $\bgamma^\ast \otimes
\bbeta^\ast$ are four bases of $A$, with $(\bgamma \otimes \bbeta,
\bgamma^\ast \otimes \bbeta^\ast)$ and $(\bgamma^\ast \otimes \bbeta,
\bgamma \otimes \bbeta^\ast)$ being two pairs of dual bases with
respect to $\ang{.,.}_I$. Our algorithms will exploit all these bases;
this is harmless, since conversions between these bases have
quasi-linear complexity.

Before giving the details of the algorithms, we make an observation
similar to the one we did regarding the transpose of Embed. Let
$\Phi^t$ be the dual map of $\Phi$ with respect to $\ang{.,}_R$ and
$\ang{.,.}_I$. Then, for any $b,b' \in k[z]/\ang{R}$, we have:
\begin{eqnarray*}
\ang{b,b'}_I=\tau_I(b b') &=&  \tau_R(\Phi(b b'))\\
&=& \ang{\Phi(b), \Phi(b')}_R \\
&=& \ang{b, \Phi^t(\Phi(b'))}_I;
\end{eqnarray*}
hence, $\Phi^t = \Phi^{-1}$. If ${\bf b}$ and ${\bf b}^\ast$ are two
bases of $A=k[x,y]/I$, dual with respect to $\ang{.,.}_I$ (such as the
ones seen above) and if ${\bf c}$ and ${\bf c}^\ast$ are two bases of
$k[z]/\ang{R}$, dual with respect to $\ang{.,.}_R$, the previous
equality, together with the transposition principle, shows the
following: if we have an algorithm for $\Phi$, expressed in the bases
(${\bf b}$, ${\bf c}$), transposing it yields an algorithm for
$\Phi^{-1}$, expressed in the bases $({\bf c}^\ast,{\bf b}^\ast)$.

\smallskip\noindent{{\bf \rm First case: $m$ is small.}}
We start by a direct application of the results in the previous
subsection, which is well-suited to situations where $m$ is small
compared to $n$.

Let $b$ be in $k[x,y]/I$ and let $a=\Phi(b)$. Writing $b=\sum_{0 \le i
  < m} b_i x^i$, with all $b_i$ in $k[y]/\ang{Q}$, we obtain a
straightforward algorithm to compute $a$: compute all $\Phi(b_i x^i)$,
using Algorithm~\ref{algo:embed}, then sum.

Since Algorithm~\ref{algo:embed} takes its inputs written on the dual
bases, the following algorithm requires all $b_i$ be written on the
dual basis of $k[y]/\ang{Q}$ (equivalently, the input is given on the
basis $\bgamma \otimes \bbeta^\ast$ of $A$). We use the further
observation that the expression of $x^i$ on the dual basis
$\bgamma^\ast$ is $\vu_P$ shifted by $i$ positions to give a slightly
more compact algorithm.

\vspace{-10pt}

\begin{algorithm_endline}
{Phi1$(\vb)$}
{$\vb = (b_{i,j})_{0 \le i < m, 0 \le j < n} \in k^{m \times n}$}
{$\va = (a_{i})_{0 \le i < mn} \in k^{m n}$}
{algo:iso1}
\item $(u_i)_{0\le i < m(n+1)-1} = \rem^t(\vu_P,P,m(n+1)-1)$
\item  $(a_i)_{0\le i < mn} = (0,\dots,0)$
\item {\bf for} {$0\le i < m$}
\item \hspace{7mm} $(t_j)_{0\le j < mn} = \rem^t( (b_{i,j})_{0 \le j <n},Q,mn)$
\item \hspace{7mm} $(a_j)_{0\le j < mn} = (a_j + t_ju_{i+j})_{0\le j < mn}$
\item {\bf return} $(a_i)_{0\le i <mn}$
\end{algorithm_endline}

\begin{Lemma}
  Let $b \in k[x,y]/I$. Given the coefficients $\vb$ of $b$ in the
  basis $\bgamma \otimes \bbeta^\ast$, {\em Phi1}$(\vb)$ computes the
  coefficients of $\Phi(b)$ in the basis $\bbbeta^\ast$ using
  $O(m^2\M(n))$ operations in~$k$.
\end{Lemma}
\begin{proof}
  Correctness follows from the previous discussion. The most expensive
  step is $m$ calls to $\rem^t$, for a cumulated cost of
  $O(m^2\M(n))$.
\end{proof}

Transposing this algorithm gives an algorithm for $\Phi^{-1}$. Its
input is given on the monomial basis $(z^i)_{0 \le i < mn}$ of
$k[z]/\ang{R}$; the output is written on the basis $\bgamma^\ast
\otimes \bbeta$ of $A$.

\begin{algorithm_endline}
{InversePhi1$(\va)$}
{$\va = (a_{i})_{0 \le i < mn} \in k^{m n}$}
{$\vb = (b_{i,j})_{0 \le i < m, 0 \le j < n} \in k^{m \times n}$}
{algo:tiso1}
\item $(u_i)_{0\le i < m(n+1)-1} = \rem^t(\vu_P,P,m(n+1)-1)$
\item $(b_{i,j}) = (0)_{0\le i < m, 0 \le j < n}$
\item {\bf for} {$i = m-1,\dots,0$}
\item \hspace{7mm} $d=\sum_{0 \le j < mn} a_j u_{i+j} y^j \bmod Q$
\item \hspace{7mm}  $(b_{i,j})_{0 \le j < n} = (\coeff(d,j))_{0 \le j < n}$
\item {\bf return} $(b_{i,j})_{0 \le i < m, 0 \le j < n}$
\end{algorithm_endline}

\begin{Lemma}
   Let $a\in k[z]/\ang{R}$. Given the coefficients $\va$ of $a$ in the
  basis $\bbbeta=(z^i)_{0 \le i < mn}$, {\em InversePhi1}$(\va)$
  computes the coefficients of $\Phi^{-1}(a)$ in the basis $\bgamma
  \otimes \bbeta^\ast$ using $O(m^2\M(n))$ operations in~$k$.
\end{Lemma}
\begin{proof}
  The correctness of this algorithm is proved as in
  Lemma~\ref{lemma:project}, observing that it consists in the
  line-by-line transposition of Phi1. The running time analysis is
  straightforward: the dominant cost is that of $m$ remainders, each
  of which costs $O(m\M(n))$.
\end{proof}

\noindent{{\bf \rm Second case: $m$ is not small.}}  The previous
algorithm is most efficient when $m$ is small; now, we propose an
alternative solution that does better when $m$ and $n$ are of the same
order of magnitude (with still $m \le n$)

This approach is based on baby steps / giant steps techniques, as in
Brent and Kung's modular composition algorithm, but uses the fact that
$z=\Phi(xy)$ to reduce the cost. Given $b$ in $A=k[x,y]/\ang{P,Q}$,
let us write
\begin{eqnarray*}
b&=&\sum_{i=0}^{m-1}\sum_{j=0}^{n-1} b_{i,j}x^i y^j\\
&=&\sum_{i=0}^{m-1}\sum_{j=0}^{n-1} b_{i,j}x^i y^i y^{j-i}\\
&=&\sum_{\ell=-m+1}^{n-1}\sum_{i=0}^{m-1} b_{i,i+\ell}(xy)^i y^\ell\\
&=&\frac{1}{y^{m-1}} \sum_{\ell=0}^{m+n-2} h_\ell(xy) y^\ell,
\end{eqnarray*}
with $h_\ell(z)=\sum_{0 \le i < m-1} b_{i,i+\ell-m+1} z^i$ for all
$\ell$ (undefined indices are set to zero); since $m \le n$, all
$h_\ell$ have indeed degree less than $m$. This implies that
$a=\Phi(b)$ has the form
$$a = \frac{1}{T^{m-1}}\widetilde{a} \mod R\quad\text{with}\quad
\widetilde{a}=\sum_{\ell=0}^{m+n-2} h_\ell T^\ell,$$ where $T=\varphi_y(y)$.
We use baby steps / giant steps techniques from~\cite{LeMeSc13}
(inspired by Brent and Kung's algorithm) to compute $a$, reducing the
problem to polynomial matrix multiplication. Let
$$n'=m+n-1,\quad p=\lceil \sqrt {n'} \rceil,\quad q=\lceil
n'/p\rceil,$$ so that $n \le n' \le 2n-1$ and $p\simeq q \simeq
\sqrt{n}$.  For baby steps, we compute the polynomials $T_i=T^i \bmod
R$, which have degree at most $mn-1$; we write $T_i = \sum_{0 \le j <
  n} T'_{i,j} z^{jm}$, with $T'_{i,j}$ of degree less than $m$, and
build the polynomial matrix $M_{T'}$ with entries $T'_{i,j}$.  We also
define the matrix $M_H=[h_{iq+j}]_{0 \le i <p, 0 \le j < q}$
containing the polynomials $h_\ell$ organized in a row-major fashion, and
compute the product $M_V=M_H M_T$. We can then recompose polynomials
from the rows of $M_V$, and conclude with giant steps, using Horner's
scheme to obtain $G$.

The previous discussion leads to Algorithm~\ref{algo:iso2}. Remark
that inputs {\em and} output are written on the monomial bases.

\begin{algofloat}
  \begin{algorithm_endline}
{Phi2$(\vb)$}      
{$\vb = (b_{i,j})_{0 \le i < m, 0 \le j < n} \in k^{m \times n}$}
{$\va = (a_{i})_{0 \le i < mn} \in k^{m n}$}
{algo:iso2}
\item $n'=m+n-1$, $p=\lceil \sqrt {n'} \rceil$, $q=\lceil n'/p\rceil$
\item $\vy={\rm MonomialToDual}((0,1,0,\dots,0),Q)$ 
\item \label{iso2:2} $T={\rm DualToMonomial}({\rm Embed}(\vu_P, \vy), R)$
\item \label{iso2:3} $U=1/T \bmod R$
\item \label{iso2:4} $T'=[T^i \bmod R]_{0 \le i \le q}$
\item $M_{T'}=[T'_{i,j}]_{0\le i < q, 0, \le j < n}$ \hfill $T'_{i,j}$ as defined above
\item $M_H=[h_{iq+j}]_{0 \le i <p, 0 \le j < q}$ \hfill $h_\ell$ as defined above
\item \label{iso2:7} $M_V = M_H M_{T'}$
\item $V=[\sum_{0 \le j <n} {M_V}_{i,j} z^{jm} ]_{0 \le i <p}$
\item $V'=[V_i \bmod R]_{0 \le i <p}$
\item $a=0$
\item {\bf for} {$i=p-1,\dots,0$}\label{iso2:11}
\item \hspace{7mm} $a=T'_q\, a+V'_i \bmod R$
\item \label{iso2:14} $a=a\, U^{m-1} \bmod R$
\item {\bf return} $(\coeff(a,i))_{0 \le i < mn}$
  \end{algorithm_endline}
\vspace{-5ex}
\end{algofloat}

\begin{Lemma}
  Let $b \in k[x,y]/I$. Given the coefficients $\vb$ of $b$ in the
  basis $\bgamma \otimes \bbeta=(x^i y^j)_{0 \le i < m, 0 \le j < n}$,
  {\em Phi1}$(\vb)$ computes the coefficients of $\Phi(b)$ in the
  basis $\bbbeta=(z^i)_{0 \le i < mn}$ using $O(\M(mn)n^{1/2}+\M(m)
  n^{(\omega+1)/2} )$ operations in~$k$.
\end{Lemma}
\begin{proof}
  Correctness follows from the discussion prior to the algorithm.  As
  to the cost analysis, remark first that $n'=O(n)$, and that $p$ and
  $q$ are both $O(\sqrt{n})$. Steps~\ref{iso2:3} and~\ref{iso2:14}
  cost $O(\M(mn)\log(mn))$ operations. Steps~\ref{iso2:4} (the baby
  steps) and the loop at Step~\ref{iso2:11} (the giant steps) cost
  $O(\sqrt{n}\M(mn))$. The dominant cost is the matrix product at
  Step~\ref{iso2:7}, which involves matrices of size $O(\sqrt{n})
  \times O(\sqrt{n})$ and $O(\sqrt{n}) \times O(n)$, with polynomial
  entries of degree $m$: using block matrix multiplication in size
  $O(\sqrt{n})$, this takes $O(\M(m) n^{(\omega+1)/2})$ operations in
  $k$.
\end{proof}

As before, writing the transpose of this algorithm gives us an
algorithm for $\Phi^{-1}$, this time written in the dual bases.  The
process is the same for the previous transposed algorithms we saw,
involving line-by-line transposition. The only point that deserves
mention is Step~\ref{step:tmatmul}, where we transpose polynomial
matrix multiplication; it becomes a similar matrix product, but this
time involving transposed polynomial multiplications (with degree
parameters $m-1$ and $m$). The cost then remains the same, and leas to
Lemma~\ref{lemma:tiso2}.

\begin{Lemma}\label{lemma:tiso2}
  Let $a\in k[z]/\ang{R}$. Given the coefficients $\va$ of $a$ in the
  basis $\bbbeta^\ast$, {\em InversePhi2}$(\va)$ computes the
  coefficients of $\Phi^{-1}(a)$ in the basis $\bgamma^\ast \otimes
  \bbeta^\ast$ using $O(\M(mn)n^{1/2}+\M(m) n^{(\omega+1)/2} )$
  operations in~$k$.
\end{Lemma}

\begin{algofloat}
  \begin{algorithm_endline}
{InversePhi2$(\va)$}
{$\va = (a_{i})_{0 \le i < mn} \in k^{m n}$}
{$\vb = (b_{i,j})_{0 \le i < m, 0 \le j < n} \in k^{m \times n}$}
{algo:tiso2}
\item $n'=m+n-1$, $p=\lceil \sqrt {n'} \rceil$, $q=\lceil n'/p\rceil$
\item $\vy={\rm MonomialToDual}((0,1,0,\dots,0),Q)$ 
\item $T={\rm DualToMonomial}({\rm Embed}(\vu_P, \vy), R)$
\item $U=1/T \bmod R$
\item $T'=[T^i \bmod R]_{0 \le i \le q}$
\item $M_{T'}=[T'_{i,j}]_{0\le i < q, 0, \le j < n}$ \hfill $T'_{i,j}$ as defined above
\item $\va = \mulmod^t(\va, U^{m-1}, R)$
\item $V'=[\ ]_{0 \le i < p}$
\item {\bf for} {$i=0,\dots,p-1$}
\item \hspace{7mm} $V'_i = \va$
\item \hspace{7mm} $\va = \mulmod^t(\va,T'_q,R)$
\item $V = [\rem^t(V'_i,R,mn+m-1)]_{0 \le i < p}$
\item $M_V = [(V_{i})_{jm,\dots,jm+2m-1}]_{0 \le i < p, 0 \le j < n}$
\item\label{step:tmatmul} $M_H = \mul^t(M_V, M_{T'},m-1,m)$
\item $H=[{M_H}_{0,0},\dots,{M_H}_{0,q-1},\dots,{M_H}_{p-1,q-1}]$
\item {\bf return} $[\coeff(h_{i-j+m-1},i)]_{0 \le i < m, 0 \le j < n}$
  \end{algorithm_endline}
\vspace{-5ex}
\end{algofloat}

\noindent{{\bf \rm Summary.}} Lemmas~\ref{lemma:algo:embed}
to~\ref{lemma:tiso2} prove Theorem~\ref{theo:main}. Indeed, for $m \le
n$, and using the $O\tilde{~}$ notation to neglect polylogarithmic
factors, our two solutions for $\Phi$ (or its inverse) have respective
costs $O\tilde{~}(m^2 n)$ and $O\tilde{~}(m
n^{(\omega+1)/2})$. Writing $\delta=mn$, the minimum of the two is
seen to be $O\tilde{~}(\delta^{2\omega/(\omega+1)})$; for $\omega \in
(2,3]$, the resulting exponent lies in $(1.333\dots, 1.5]$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{The algebraic closure of $\F_p$}

In this section, we explain how the algorithms of
Section~\ref{sec:emb-iso} can be used in order to construct and work
in arbitrary extensions of $\F_p$, when used in conjunction with 
algorithms for defining {\em towers} over $\F_p$.


%% \paragraph{Composed products} In addition, we assume that given a finite field
%% $\K$, and irreducible polynomials $P$ and $Q$ in $\K[x]$, we can
%% compute the composed product $R = P \otimes Q$, and perform the
%% related embedding and change of basis operations, as in the previous
%% section.

\paragraph*{{\bf \rm Setup}} For $\ell$ prime and $i \ge 1$, define
$\K_{\ell^i}=\F_p[x_1,\dots,x_i]/\langle
T_{\ell,1},\dots,T_{\ell,i}\rangle$. This is a field with $\ell^i$
elements.  The residue class of $x_i$ in $\K_{\ell^i}$ will be written
$x_{\ell^i}$.

Fix a positive integer $m=\ell_1^{e_1}\cdots \ell_r^{e_r}$, with
$\ell_i$ pairwise distinct primes and $e_i$ positive integers.  Define
$\K_m$ as the tensor product $\K_{\ell_1^{e_1}} \otimes \cdots \otimes
\K_{\ell_r^{e_r}}$; this is a field with $p^m$ elements.  If $m$
divides $n$, then $\K_m$ embeds in $\K_n$. Taking the direct limit of
all $\K_m$ under such embeddings, we get an algebraic closure $\K$ of
$\F_p$. The residue classes written $x_{\ell^i}$ in $\K_{\ell^i}$ all
lie in $\K$ and are still written $x_{\ell^i}$.

For any integer $n$ of the form $n=\ell_1^{c_1}\cdots \ell_s^{c_s}$
with $\ell_i$ pairwise distinct primes, we write $x_n =
x_{\ell_1^{c_1}} \cdots x_{\ell_s^{c_s}} \in \K$.

\paragraph*{{\bf \rm Minimal polynomials}}
First, we discuss minimal polynomials of (residue classes of)
monomials, either over $\F_p$ or over an intermediate field.

Consider a residue class $x_{\ell^{c}}$, with $\ell$ a prime. Its
minimal polynomial over $\F_p$ is $Q_{\ell^c}=Q_{\ell,c}(Z)$,
irreducible of degree $\ell^{c}$ in $\F_p[Z]$. Next, consider the term
$x_m$, with $m=\ell_1^{e_1}\cdots \ell_r^{e_r}$, with all $\ell_i$'s
pairwise distinct primes. This term equals $x_{\ell_1^{e_1}} \cdots
x_{\ell_r^{e_r}}$, so it is a root of $Q_{m}=Q_{\ell_1^{e_1}} \otimes
\cdots \otimes Q_{\ell_r^{e_r}}.$ Since $Q_m$ is irreducible of degree
$m=\ell_1^{e_1}\cdots \ell_r^{e_r}$ in $\F_p[Z]$, it is the minimal
polynomial of $x_m$.  In particular, this last fact implies that
$\F_p(x_m)$ is a field with $p^m$ elements, and that if we consider
terms $x_m$ and $x_n$, with $m$ dividing $n$, then $x_m$ is in
$\F_p(x_n)$.

Conversely, with $m$ and $n$ as above, we are now going to describe
the minimal polynomial of $x_n$ over $\F_p(x_m)$. Without loss of
generality, we can assume that $m$ and $n$ are written
$m=\ell_1^{e_1}\cdots \ell_r^{e_r}$ and
$n=\ell_1^{g_1}\cdots\ell_r^{g_r}$, with $e_i \le g_i$ for all $i$.
The minimal polynomial of $x_{\ell_i^{g_i}}$ over
$\F_p(x_{\ell_i^{c_i}})$ is $Q_{\ell_i,c_i,g_i}(x_{\ell_i^{c_i}},Z)$.
Since $\F_p(x_m)$ is an extension of $\F_p(x_{\ell_i^{c_i}})$ of
degree coprime to $\ell_i$, and since the former polynomial has degree
$\ell_i^{g_i-c_i}$, it remains irreducible in $\F_p(x_m)[Z]$. We
deduce that the minimal polynomial of $x_n = x_{\ell_1^{g_1}}\cdots
x_{\ell_r^{g_r}}$ over $\F_p(x_m)$ is $Q_{m,n}=Q_{\ell_1,c_1,g_i}
\otimes \cdots \otimes Q_{\ell_r,c_r,g_r}.$ It has degree
$n/m=\ell_1^{g_1-c_1}\cdots \ell_r^{g_r-c_r}$.

\paragraph*{\bf \rm {Embedding and change of basis}}
Consider a sequence $d=(d_1,\dots,d_s)$ of positive integers, and let
$m=d_1 \cdots d_s$. The set
$$B_d = \{ x_{d_1}^{e_1} x_{d_1 d_2}^{e_2} \cdots x_{d_1 \cdots
  d_s}^{e_1} \mid 0 \le e_i < d_i \}$$ is a basis of $\F(x_m)$. Our
main examples are sequences of the form $d=(d_1)$, with thus $m=d_1$,
for which $B_d$ is the univariate basis $(x_m^i)_{0 \le i < m}$.

Consider two such sequences $d=(d_1,\dots,d_s)$ and
$e=(e_1,\dots,e_t)$, with $m=d_1 \cdots d_s$ and $n=e_1 \cdots e_t$,
and suppose that $m$ divides $n$. The embedding $\F_p^{B_d} \to
\F_p^{B_e}$ is denoted by $\Phi_{e,d}$; when $m=n$, it is an
isomorphism, with inverse $\Phi_{d,e}$.

As soon as this expression makes sense, we have $\Phi_{f,d} =
\Phi_{f,e}\circ \Phi_{e,d}$.

\paragraph*{\bf \rm {Basic algorithms}}
Let us now examine how to apply mappings such as $\Phi_{e,d}$.
Suppose that $d=(d_1,\dots,d_s)$. Then, the following operations are
available to us:
\begin{itemize}
\item[$A_1$] Suppose that $\gcd(d_i,d_{i+1})=1$, and let $e$ be
  obtained from $d$ by swapping $d_i$ and $d_{i+1}$. Then $\Phi_{e,d}$
  is a permutation.
\item[$A_2$] Suppose that $e$ is obtained by replacing $d_i$ by $d'_i,
  d''_i$, with $d_i = d'_i d''_i$ and $\gcd(d'_i,d''_i)=1$. Then one
  can compute $\Phi_{e,d}$, or $\Phi_{d,e}$, by applying the change of
  basis algorithm, or its inverse, with coefficients in
  $\F_p^{B_c}$, with $c=(d_1,\dots,d_{i-1})$.
\item[$A_3$] Suppose that $e$ is obtained by replacing $d_i$ by $d_i
  d'_i$, with $\gcd(d_i, d'_i)=1$. Then one can compute $\Phi_{e,d}$,
  or invert it when possible, by applying the embedding algorithm,
  with coefficients in $\F_p^{B_c}$, with $c=(d_1,\dots,d_{i-1})$.
\item[$A_4$] Suppose that $d_1=\ell^{e_1}$ and $d_2=\ell^{e_2}$, for some
  prime $\ell$, and that $e$ is obtained by replacing $d_1,d_2$ by
  $d_1 d_2=\ell^{e_1+e_2}$. Then one can compute $\Phi_{e,d}$, or
  $\Phi_{d,e}$, by applying the $\ell$-adic change of basis algorithm,
  or its inverse. 
\item[$A_5$] Suppose that $d_1=\ell^{e_1}$, for some prime $\ell$, and that
  $e$ is obtained by replacing $d_1$ by $\ell^{e_1+e_2}$. Then one can
  compute $\Phi_{e,d}$, invert it when possible, by applying the
  $\ell$-adic embedding algorithm, or its inverse. 
\end{itemize}

\paragraph*{{\bf \rm Concrete procedures}} Suppose that $m$ divides $n$. We 
describe here how to embed $\F_p(x_m)$ in $\F_p(x_n)$, that is, how to
compute $\Phi_{(n),(m)}$. Write $m= \ell_1^{f_1}\cdots \ell_r^{f_r}$
and $n = n' \ell_1^{e_1}\cdots \ell_r^{e_r}$, where all $\ell_i$ are
primes and $\gcd(m,n')=1$; in particular, $f_i \le e_i$ holds for all
$i$.

Let $d=(\ell_1^{f_1},\dots,\ell_r^{f_r})$. Applying $A_2$ repeatedly,
we can compute $\Phi_{d,(m)}$. For $i=1,\dots,r$, do the following:
apply $A_1$ as needed to bring the factor $\ell_i^{f_i}$ to the first
position, then $A_5$ to replace $\ell_i^{f_i}$ by $\ell_i^{e_i}$ and
finally $A_1$ again to put that term back at $i$th position; this
allows us to compute $\Phi_{d',d}$, with
$d'=(\ell_1^{e_1},\dots,\ell_r^{e_r})$.  Apply $A_2$ repeatedly, to
compute $\Phi_{d'',d'}$, with $d''=(\ell_1^{e_1}\cdots\ell_r^{e_r})$.
Finally, use $A_3$ to compute $\Phi_{(n),d''}$.

Our second example is how to compute $\Phi_{(m,n), (mn)}$;
equivalently, how to convert from the univariate basis $(x_{mn}^i)_{i
  < mn}$ to the bivariate one $(x_m^i x_{mn}^j)_{i < m, j < n}$.

Write $m = m' \ell_1^{e_1}\cdots \ell_r^{e_r}$ and $n = n'
\ell_1^{f_1}\cdots \ell_r^{f_r}$, with
$\gcd(m',n')=\gcd(m',\ell_i)=\gcd(n',\ell_i)=1$ for all $i$; in
particular, $mn = m' n' \ell_1^{e_1+f_1}\cdots \ell_r^{e_r+f_r}$.
Apply $A_2$ in order to compute $\Phi_{d,(mn)}$, with $d =
(\ell_1^{e_1+f_1}\cdots\ell_r^{e_r+f_r}, m', n')$. As above, apply
repeatedly $A_1$, then $A_4$ and $A_1$, in order to compute
$\Phi_{d',d}$, with $d'=(\ell_1^{e_1},\dots, \ell_r^{e_r},
m',\ell_1^{f_1},\dots,\ell_r^{f_r}, n')$. Apply $A_2$ repeatedly
to compute $\Phi_{(m,n),d'}$.

With this, we can do $+,\times$ over the algebraic closure (embed the
operands in a common extension), relative characteristic and minimal
polynomials (and thus traces and norms), and probably most other
required operations.


\scriptsize
\bibliographystyle{plain} \bibliography{defeo}

\end{document}




% Local Variables:
% mode:flyspell
% ispell-local-dictionary:"american"
% mode:TeX-PDF
% mode:reftex
% End:

% LocalWords:  embeddings bilinear
