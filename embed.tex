\documentclass[12pt]{article}

\usepackage{bbm,fullpage}
\usepackage{amsmath}
\usepackage{alltt, amssymb,stmaryrd,amsthm}
\usepackage{color}

\usepackage{algorithm}
\usepackage{algorithmic}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\def\C {\ensuremath{\mathsf{C}}}
\def\M {\ensuremath{\mathsf{M}}}
\def\Q {\ensuremath{\mathbb{Q}}}
\def\N {\ensuremath{\mathbb{N}}}
\def\R {\ensuremath{\mathbb{R}}}
\def\Z {\ensuremath{\mathbb{Z}}}
\def\F {\ensuremath{\mathbb{F}}}
\def\H {\ensuremath{\mathbb{H}}}
\def\K {\ensuremath{\mathbb{K}}}
\def\Kbar {\ensuremath{\overline{\mathbb{K}}}}
\def\L {\ensuremath{\mathbb{L}}}
\def\A {\ensuremath{\mathbb{A}}}

\def\mul {\ensuremath{\mathrm{mul}}}
\def\div {\ensuremath{\mathrm{div}}}
\def\rem {\ensuremath{\mathrm{rem}}}
\def\cat {\ensuremath{\mathrm{cat}}}
\def\coeff {\ensuremath{\mathrm{coefficient}}}
\def\mulmod {\ensuremath{\mathrm{mulmod}}}
\def\rev {\ensuremath{\mathrm{rev}}}
\def\x {\ensuremath{\mathbf{x}}}
\def\Tr {\ensuremath{\mathrm{Tr}}}

\newcommand{\ang}[1]{\langle#1\rangle}

\newcommand{\wrt}{\vdash} 
\newcommand{\todo}[1]{\textcolor{red}{TODO: #1}}
\newtheorem{Def}{Definition}
\newtheorem{Theo}{Theorem}
\newtheorem{Prop}{Proposition}
\newtheorem{Lemma}{Lemma}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Trace representation of polynomial quotient rings}

Let $k$ be a field, $s$ a positive integer, and $I$ a radical ideal in
$k[x_1,\dots,x_s]$ such that $A=k[x_1,\dots,x_s]/I$ is a finite
extension of $k$ (i.e., $I$ is zero dimensional).

We define the \emph{trace} of an element $a\in A$ as the trace of the
multilplication-by-$a$ endomorphism, and denote it by $\tau_{A/k}(a)$,
or $\tau_I(a)$, or simply $\tau(a)$ when $I$ is clear from the
context.  Equivalently, since $I$ is radical, we have
\begin{equation}\label{eq:tr}
\tau_{I}(a)=\sum_{\x \in V} a(\x),
\end{equation}
where $V=V(I)$ lies in $\overline{k}^s$~\cite{todo}.

Thanks again to $I$ being radical~\cite{todo}, the trace defines a
non-degenerate bilinear form on $A\times A$
\begin{equation}
  \label{eq:trace-def}
  \ang{a,b} = \tau(ab).
\end{equation}
Denote by $A^\ast$ the space of $k$-linear forms on $A$. By the
non-degeneracy of the trace we obtain a vector space isomorphism
\begin{equation}
  \label{eq:trace-isom}
  \begin{aligned}
  \phi_\tau : A &\to A^\ast,\\
            a &\mapsto a\cdot\tau,
  \end{aligned}
\end{equation}
where $a\cdot\tau$ is the linear form $x\mapsto\tau(ax)$. Then, to any
$k$-vector space basis $(b_i)_i$ of $A$, we can associate a unique
\emph{dual basis} $(b_i^\ast)_i$ such that
\begin{equation}
  \label{eq:dual-basis}
  \ang{b_i,b_j^\ast} = \phi_\tau(b_i^\ast)(b_i) = \begin{cases}
    1 &\text{if $i=j$,}\\
    0 &\text{otherwise}.
  \end{cases}
\end{equation}
When there is a natural choice for the basis of $A$ (e.g., $I$ is a
triangular ideal and elements are represented on its natural monomial
basis), by \emph{the} dual basis we will mean the basis dual to the
natural one.

The goal of this paper is to show that dual bases are an excellent
tool to work efficiently in subextensions of $A/k$. In the next
sections we \dots %todo

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Basic algorithms}

In this section, we review several known algorithms for the special
case where $I=\ang{P}$ or $I=\ang{P,Q}$. We give
pseudo-code for those that cannot be found in standard references such
as~\cite{vzGG}, and that are not available in standard computer
algebra systems.

We denote by $\M:\N \to \N$ a function such that polynomials in
$\F[X]$ of degree at most $n$ can be multiplied in $\M(n)$ operations
in $\F$, and we make the usual super-linearity assumptions on
$\M$~\cite[Chapter~8]{vzGG}. We also denote by $\omega$ a constant in
$(2,3]$ such that one can multiply matrices of size $n$ over $\F$
using $O(n^\omega)$ operations in $\F$.

Given variables $X_1,\dots,X_s$ and integers $d_1,\dots,d_s$,
$\F[X_1,\dots,X_s]_{d_1,\dots,d_s}$ denotes the set of polynomials $P$
in $\F[X_1,\dots,X_s]$ such that $\deg(P,X_i) < d_i$ holds for all
$i$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Polynomial multiplication and remainder}

For $B$ in $\F[X]$ of degree at most $m$, it will be convenient to let
$$
\begin{array}{cccc}
\mul(.,B,m,k): &\F[X]_k& \to &\F[X]_{k+m}\\
& A & \mapsto & AB
\end{array}$$ 
denote the multiplication-by-$B$ operator, which can be applied using
$\M(\max(m,k))$ operations in $\F$. In a similar vein, we denote by
$$
\begin{array}{cccc}
\rev(.,m): &\F[X]_m &\to& \F[X]_m  \\
& F & \mapsto & X^{m-1} F(1/X)
\end{array}$$ the reversal operator. 

Next, fix a monic polynomial $P$ of degree $m$ in $\F[X]$. For $k \ge 1$, we denote by
$\rem(.,P,k)$ the operator
$$
\begin{array}{cccc}
\rem(.,P,k): &\F[X]_k& \to &\F[X]_{m}\\
& A & \mapsto & A \bmod P.
\end{array}$$ 
Such remainders can be computed in time $O(\M(\max(k,m)))$ using the
Cook-Sieveking-Kung algorithm~\cite[Chapter~9]{vzGG}. For $B$
in $\F[X]/\langle P \rangle$ we will also use the modular multiplication
operator
$$\begin{array}{cccc} \mulmod(.,B,P): & \F[X]/\langle P \rangle & \to
  & \F[X]/\langle P \rangle\\ & A & \mapsto & AB \bmod P.
\end{array}$$ 
Identifying $\F[X]_m$ and $\F[X]/\langle P \rangle$, and using the
direct algorithm for modular multiplication (multiply, then reduce),
we can write 
\begin{equation}
  \label{eq:mulmod}
  \mulmod(.,B,P) = \rem(.,P,2m-1) \circ \mul(.,B,m-1,m).
\end{equation}
One can thus compute $\mulmod(A,B,P)$ using $O(\M(m))$ operations in
$\F$, as is well known.

Finally, we say a brief word about bivariate algorithms.  Given two
integers $d,e$, we denote by
$$
\begin{array}{cccc}
\rev(.,d,e): &\F[X,Y]_{d,e} &\to& \F[X,Y]_{d,e}  \\
& F & \mapsto & X^d Y^e F(1/X,1/Y)
\end{array}$$
the operator that reverses a polynomial $F$ with respect to both $X$
and $Y$ (and does not require any arithmetic operation).

Given $P$ and $Q$ monic in respectively $\F[X]$ and $\F[Y]$, 
and given $B$ in $\F[X,Y]/\langle P,Q\rangle$, we will use the
bivariate modular multiplication operator
$$\begin{array}{cccc} \mulmod(.,B,\langle P,Q \rangle): & \F[X,Y]/\langle P,Q \rangle & \to
  & \F[X,Y]/\langle P,Q \rangle\\ & A & \mapsto & AB \bmod \langle P, Q \rangle.
\end{array}$$ 
Applying this operator takes $O(\M(de))$ operations in $\F$ (todo: ref).


\subsection{Algorithms for the dual basis}
\label{sec:algor-dual-basis}

Next, we briefly review some algorithms dealing with the dual basis
representation.  We start by considering the vector space $k[x]_m$,
represented on the standard polynomial basis $(x^i)_{i<m}$. We
identify its dual space $k[x]_m^\ast$ with $k^m$, and we consider the
natural non-degenerate bilinear form on $k[x]_m^\ast\times k[x]_m$
given by evaluation of linear forms: $\ang{\ell,a} = \ell(a)$.

Mutliplication by a fixed $b\in k[x]_m$ is a linear map
\begin{equation*}
  M_b: k[x]_n \to k[x]_{m+n}
\end{equation*}
for any positive integer $n$. By definition, its \emph{dual} (or
\emph{transpose}, especially when talking about algorithms) is a
linear map
\begin{equation*}
  M_b^t : k^{m+n} \to k^n
\end{equation*}
such that
\begin{equation*}
  \ang{\ell,M_b(a)} = \ang{\ell,ab} = \ang{M_b^t(\ell),a}.
\end{equation*}

We denote by $\mul^t(.,b,m,n)$ an algorithm to compute $M_b^t$ for
fixed $b$ of degree $m$, and for fixed $0\le n\le m$. To implement it,
one can use \emph{transposed versions} of plain, Karatsuba and FFT
algorithms~\cite{bostan+lecerf+schost:tellegen,hanrot+quercia+zimmermann},
which have the same running time, up to an extra $O(m)$.  By
identifying $k[X]_n$ with its dual, one can also see $\mul^t(.,b,m,n)$
mapping $k[X]_{m+n}$ to $k[X]_{n}$ and notice that $\mul^t(.,b,m,n)$
then becomes $$a \in k[X]_{m+n} \mapsto (a\ \rev(b,m+1) \bmod
x^{m+n}){\rm~div~}x^{m} \in k[X]_n.$$ This formula leads to algorithms
for the transposed product that can be implemented using only
``classical'' polynomial multiplication, but are slower than those
of~\cite{bostan+lecerf+schost:tellegen,hanrot+quercia+zimmermann} by a
constant factor.

The reversal operator on $k[x]_m$ is its own dual. Finally, we
consider $A=k[x]/\ang{P}$, with $P$ monic of degree $m$, and
we discuss the tranposes of $\rem$ and $\mulmod$.  The \emph{monomial
  basis} of $A$ is made up of the monomials $x^i$ for $0\le i<m$, and
we denote by $(x^i)^\ast$ the elements of its dual basis.

As shown in~\cite{bostan+lecerf+schost:tellegen}, the dual map
$$
\begin{array}{cccc}
\rem^t(.,P,n): &k^m& \to &k^n
\end{array}$$ 
takes as input a linear form $\ell\in A^\ast$ expressed on the basis $(x^i)^\ast$; the output
is then the values $(\ell(x^i))_{0 \le i < k}$. For $n \le m$, there
is nothing to do. For greater values of $n$, $\rem^t$ is \emph{linear sequence extension}: it takes as input the initial $m$ values of a linear recurring sequence of minimal polynomial $P$, and outputs its first $n$ values.

LFSRs give a simple, though suboptimal, implementation of this
operator~\cite{todo}. The transposed version of the
Cook-Sieveking-Kung fast Euclidean division algorithm yield better
algorithms, as explainted in~\cite{bostan+lecerf+schost:tellegen}:
like for the forward direction the cost of the transposed algorithm is
$O(\M(n))$ if $n>m$. We recall this below.

\begin{algorithm}[H]
  \caption{$\rem^t(\ell,P,k)$}
  \begin{algorithmic}[1]
    \REQUIRE $\ell=(\ell_i)_{0 \le i < m}$, $P$ in $k[X]$ monic of degree $m$, $n \ge m$
    \STATE $S = 1/\rev(P, m+1) \bmod x^{n-m}$
    \STATE $A = \mul^t( \sum_{0 \le i < m} \ell_{i}x^i, P, m, n-m)$
    \STATE $C = S A \bmod x^{n-m}$
    \STATE $D = \ell ~\cat~ (-\coeff(C,i))_{0 \le i < n-m}$
    \RETURN $D$
  \end{algorithmic}
\end{algorithm}

Finally, multiplication by a fixed $b\in A$ is a linear map $M_b:A\to
A$. By definition
\begin{equation}
  \label{eq:mulmodt-def}
  \ang{M_b^t(a),c} = \ang{a,M_b(c)} = \ang{a,bc} = \tau_P(abc).
\end{equation}
Hence, if $a$ is written on the dual basis, the transposed map
$\mulmod^t(.,b,P)$ maps a linear form $\ell = a\cdot\tau_P$ to the
linear form $b \cdot \ell=ab\cdot\tau_P$.  

From Eq.~\eqref{eq:mulmod},
we obtain the following algorithm $\mulmod^t$, costing $O(\M(m))$
operations in $k$ (see
also~\cite{shoup99,bostan+lecerf+schost:tellegen}).


\begin{algorithm}[H]
  \caption{$\mulmod^t(\ell,b,P)$}
  \begin{algorithmic}[1]
    \STATE $D = \rem^t(\ell,P,2m-1)$
    \RETURN $\mul^t(D, b, m-1, m)$
  \end{algorithmic}
\end{algorithm}

Algorithms for $\mulmod^t$ have been subject to much
research. Berlekamp's \emph{bit serial multiplication}~\cite{todo} is
a popular arithmetic circuit for transposed modular multiplication in
the case $k=\F_2$. It can be understood as a transposed Horner
rule, hence its software version is suboptimal.

Given an algorithm for $\mulmod^t$ one can multiply two elements
represented on the dual basis by converting one to the monomial basis,
and then applying $\mulmod^t$. Since $\mulmod^t$ has the same cost as
$\mulmod$~\cite{shoup99,bostan+lecerf+schost:tellegen}, this is better
than converting both elements to the monomial basis.

Much research has gone in finding polynomials $P$ that make the
conversion between the monomial and the dual basis cheap. An open
question is whether there exists a better algorithm to multiply two
elements directly in the dual basis.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Trace formulas} 
\label{sec:trace-formulas}

We now describe algorithms for converting between the monomial and the
dual basis. We discuss the univariate case first, then the bivariate
briefly.

%todo

\paragraph{Univariate formulas.} In this paragraph, we fix $B$ in $\L$ and we 
denote by $M_{I,B} \in \F[X]$ the minimal polynomial of $B$. If we let
$V_B \subset \overline{F}$ be the image of $V$ under the mapping $\x \mapsto
B(\x)$, then $M_{I,B}$ is the polynomial $\prod_{\beta \in
  V_B}(X-\beta)$.

The subfield $\F(B) \subset \L$ is isomorphic to $\F[X]/\langle
M_{I,B} \rangle$. We may then consider the trace
${\rm Tr}_{\L/\F(B)}$, which we see as an $\F[X]/\langle
M_{I,B}\rangle$-linear mapping
$$
\begin{array}{cccc}
\tau_{I,B} :& \L& \to& \F[X]/\langle M_{I,B} \rangle.
\end{array}$$
The trace ${\rm Tr}_{\L/\F(B)}$ is $n$ times the identity on $\F(B)$,
where we denote by $n$ the index $[\L:\F(B)]$. In particular, if
$A=C(B)$, for some polynomial $C$ in $\F[X]$, then $\tau_{I,B}(A)=n
\ C \bmod M_{I,B}$.

The following lemma shows how to relate $\tau_{I,B} (A)$ to the
sequence $\tau_I(A B^i)$. This is a restatement of well-known results,
see for instance~\cite{rouiller99}. In what follows, we sometimes
identify $\tau_{I,B}(A)$, which lies in $\F[X]/\langle M_{I,B} \rangle$,
to its canonical preimage in $\F[X]$.

\begin{Lemma}\label{lemma:trace:1}
  For $A$ and $B$ in $\L$, 
  $$\sum_{i \ge 0} \tau_I(A B^i) X^i = \frac{\rev( M'_{I,B}\, \tau_{I,B}
    (A) \bmod M_{I,B},m)}{\rev(M_{I,B},m+1)},$$ where
  $m=\deg(M_{I,B})$.
\end{Lemma}
\begin{proof}
First, remark that for $A$ in $\L$, $\tau_{I}(A)$ is such that for all
$\beta$ root of $M_{I,B}$ (that is, for $\beta$ in $V_B$), we have
\begin{equation}\label{eq:TrB}
\tau_{I,B}(A)(\beta) = \sum_{\x \in V,\, B(\x)=\beta} A(\x).  
\end{equation}
Then, starting from Equation~\eqref{eq:tr} and summing the geometric
series that arises, we obtain
\begin{eqnarray*}
\sum_{i \ge 0} \tau_I(A B^i) X^i &=& \sum_{\x \in V} \sum_{i \ge 0} A(\x)B(\x)^i X^i\\
&=& \sum_{\x \in V} \frac{A(\x)}{1-B(\x)X}\\
&=& \frac{\sum_{\beta \in V_B} \sum_{\x \in V,\, B(\x)=\beta} A(\x) \prod_{\beta'\ne \beta} (1-\beta' X)}
    {\prod_{\beta \in V_B}(1-\beta X)}\\
&=& \frac{\rev(N,m)}{\rev(M_{I,B},m+1)},
\end{eqnarray*}
where $N$ is the polynomial
$$\sum_{\beta \in V_B}\ \sum_{\x \in V,\, B(\x)=\beta} A(\x) \prod_{\beta'\ne \beta} (X-\beta' ).$$
In particular, for  $\beta$ in $V_B$, $N(\beta)=\sum_{\x \in V,\, B(\x)=\beta} A(\x) \prod_{\beta'\ne \beta} (X-\beta' )$,
which coincides with $M'_{I,B}(\beta)\sum_{\x \in V,\, B(\x)=\beta} A(\x)$.
Comparing with Equation~\eqref{eq:TrB}, we obtain 
$N=M'_{I,B}\, \tau_{I,B}(A) \bmod M_{I,B}$.
\end{proof}

As a first application, we consider the case where $M_{I,B}$ is known,
and we want to compute several traces of the form $\tau_I(B^i)$, for
$i=0,\dots,k-1$, for some $k \ge m$. In this case, taking $A=1$, the
previous lemma shows that the sequence $(\tau_I(B^i))_{i \ge 0}$ is
the coefficient sequence of the power series
  $$ \frac{n\, \rev(M'_{I,B} ,m)}{\rev(M_{I,B},m+1)}.$$ This leads to
the following classical algorithm.

\begin{algorithm}[H]
  \caption{TraceFromMinpoly$(M_{I,B}, n, k)$}
  \begin{algorithmic}[1]
    \REQUIRE  $M_{I,B}$ monic in $\F[X]$ of degree $m$, $k \ge 1$, $n=[\L:\F(B)]$    
    \ENSURE $(\tau_I(B^i))_{0 \le i < k}$
    \STATE\label{algo:minpolytotrace:1} $D = n\, \rev(M'_{I,B}, m)/\rev(M_{I,B}, m+1) \bmod X^k$
    \RETURN $(\coeff(D,i))_{0 \le i < k}$
  \end{algorithmic}
  \label{algo:minpolytotrace}
\end{algorithm}

\begin{Lemma}\label{lemma:computetrace}
  Algorithm~\ref{algo:minpolytotrace} correctly computes
  $(\tau_I(B^i))_{0 \le i < k}$ in time $O(\M(k))$.
\end{Lemma}

%todo

 one may use Newton
iteration (as in~\cite{Schoenhage82}) if the characteristics of $\F$
is greater than $mn$; in general, we use the Berlekamp Massey
algorithm (or rather a fast variant thereof), which is slightly slower
($O(\M(mn)\log(mn))$ instead of $O(\M(mn))$). In any case, 
this is quasi-linear (previous algorithms were at least quadratic,
see the discussion in~\cite{BoFlSaSc06}).
%todo

As a second application, we consider $A$ in $\F(B)$. Given traces of
the form $\tau_I(A B^i)$, we want to express $A$ as a polynomial in
$B$ (the natural context for this kind of algorithm is a situation
where we do not have access to $A$ itself but can indirectly compute
values of the form $\tau_I(A B^i)$). Various forms of this algorithm
were already known, such as Shoup's~\cite{shoup94} (which did not use
traces, but random linear forms) or Rouillier's~\cite{rouiller99}.

\begin{algorithm}[H]
  \caption{ConvertFromTrace$(t, M_{I,B}, n)$}
  \begin{algorithmic}[1]
    \REQUIRE  $t=(\tau_I(A B^i))_{0 \le i < m}$, $M_{I,B}$ monic in $\F[X]$ of degree $m$, $n=[\L:\F(B)]$
    \ENSURE $C$ in $\F[X]_m$
    \STATE $D =  1/M'_{I,B} \bmod M_{I,B}$
    \STATE $N=\rev(M_{I,B}, m+1)( \sum_{0 \le i <m} t_i X^i) \bmod X^m$
    \STATE $N^\star = \rev(N, m)$
    \STATE $C=\mulmod(N^\star, D, M_{I,B})$
    \RETURN $C/n$
  \end{algorithmic}
  \label{algo:tracetopoly}
\end{algorithm}

\begin{Lemma}
  Suppose that $n=[\L:\F(B)]$ is a unit in $\F$. If $A$ is in
  $\F(B)$, Algorithm~\ref{algo:tracetopoly} computes a polynomial $C$
  such that $A=C(B)$ in time $O(\M(m)\log(m))$.
\end{Lemma}
\begin{proof}
  Correctness follows from the remark made before
  Lemma~\ref{lemma:trace:1} that $\tau_{I,B}(A)=n \ C \bmod M_{I,B}$,
  together with the following consequence of Lemma~\ref{lemma:trace:1}:
$$ \rev( M'_{I,B}\, \tau_{I,B}  (A) \bmod M_{I,B},m) = \rev(M_{I,B},m+1) \left (\sum_{i \ge 0} \tau_I(A B^i) X^i \right )  \bmod X^m.$$
  As to the running time, the dominant part is the computation of $D$,
  which takes time $O(\M(m)\log(m))$.
\end{proof}

For latter use, we mention the transpose of algorithm
ConvertFromTrace; since the former takes as input the values of a
linear form and outputs a polynomial, the transpose will actually do
the same. As it turns out, this mapping is symmetric: this is easier
to see when considering its inverse, whose matrix in the canonical
bases is the Hankel matrix with entries $\tau_I(B^{i+j})$.

%% Remark that the non-linear part of the computation
%% (computing $D$) does not change and that all other steps are simply
%% reversed, and replaced by their transposes. The running time remains
%% $O(\M(m)\log(m))$.

%% \begin{algorithm}[H]
%%   \caption{ConvertFromTrace$^t(C,M_{I,B},n)$}
%%   \begin{algorithmic}[1]
%%    \REQUIRE $C=(c_i)_{0 \le i <m}$, $M_{I,B}$ monic in $\F[X]$ of degree $m$, $n=[\L:\F(B)]$
%%    \ENSURE  $T \in \F[X]_m$
%%     \STATE $D =  1/M'_{I,B} \bmod M_{I,B}$
%%     \STATE $(N^\star_i)_{0 \le i < m}=\mulmod^t(C/n, D, M_{I,B})$
%%     \STATE $N = (N^\star_{m-1-i})_{0 \le i < m}$
%%     \STATE $(T_i)_{0 \le i < m}=\mulmod^t(N, \rev(M_{I,B},m+1), X^m)$
%%     \RETURN $T=\sum_{0 \le i < m} T_i X^i$
%%   \end{algorithmic}
%% \end{algorithm}


\paragraph{Trace formulas: bivariate case.} 
Let $\L$ be as above. Consider $B$ and $C$ in $\L$, Below, we will
take the minimal polynomials $M_{I,B}$ and $M_{I,C}$ of respectively
$B$ and $C$ in respectively $\F[X]$ and $\F[Y]$, and we will assume
that $\F(B)$ and $\F(C)$ are linearly disjoint, so that $\F(B,C) \simeq
\F[X,Y]/\langle M_{I,B}, M_{I,C}\rangle$. Thus, the trace ${\rm
  Tr}_{\L/\F(B,C)}: \L \to \F(B,C)$
can be written as 
$$\begin{array}{cccc}
\tau_{I,B,C} :& \L& \to& \F[X,Y]/\langle M_{I,B}, M_{I,C} \rangle.
\end{array}$$
In this context, we can write a bivariate version of Lemma~\ref{lemma:trace:1}.
\begin{Lemma}
  Let $A, B, C$ be in $\L$, such that $\F(B)$ and $\F(C)$ are linearly
  disjoint, and let $M_{I,B}\in \F[X]$ and $M_{I,C}\in \F[Y]$ be the
  minimal polynomials of respectively $B$ and $C$. Then,
  $$\sum_{i,j \ge 0} \tau_I(A B^i C^j) X^i Y^j= 
  \frac{\rev( M'_{I,B}\, M'_{I,C}\, \tau_{I,B,C} (A) \bmod \langle M_{I,B}, M_{I,C}\rangle,m,n)}{\rev(M_{I,B},m+1)\, \rev(M_{I,C},n+1)},$$
  with $m=\deg(M_{I,B})$ and $n=\deg(M_{I,C})$.
\end{Lemma}
\begin{proof}
  Let us now denote by $V_{B,C}$ the image of $V$ under the mapping
  $\x \mapsto (B(\x),C(\x))$. Under the linear disjointness
  assumption, this is simply $V_B \times V_C$. As in the proof of
  Lemma~\ref{lemma:trace:1}, we now have, for $\beta$ in $V_B$ and $\gamma$ in $V_C$,
  \begin{equation}\label{eq:TrBC}
    \tau_{I,B,C}(A)(\beta,\gamma) = \sum_{\x \in V,\, B(\x)=\beta,\, C(\x)=\gamma} A(\x).  
  \end{equation}
  Still proceeding as in the previous lemma, we have
\begin{eqnarray*}
\sum_{i,j \ge 0} \tau_I(A B^i C^j) X^i Y^j &=& \sum_{\x \in V}  \frac{A(\x)}{(1-B(\x)X)(1-C(\x)Y)}\\
&=& \sum_{(\beta,\gamma) \in V_{B,C}} \frac{\sum_{\x \in V,\, B(\x)=\beta,\, C(\x)=\gamma} A(\x)}{(1-\beta X)(1-\gamma Y)}\\
&=&\frac{\sum_{(\beta,\gamma) \in V_{B,C}} \sum_{\x \in V,\, B(\x)=\beta,\, C(\x)=\gamma} A(\x)
  \prod_{\beta'\ne \beta} (1-\beta X) \prod_{\gamma' \ne \gamma} (1-\gamma Y)}
  {\rev(M_{I,B},m+1) \rev(M_{I,C},n+1) }\\
&=& \frac{\rev(N,m,n)}  {\rev(M_{I,B},m+1) \rev(M_{I,C},n+1) },
\end{eqnarray*}
with 
$$N = \sum_{(\beta,\gamma) \in V_{B,C}} \sum_{\x \in V,\, B(\x)=\beta,\, C(\x)=\gamma} A(\x)
  \prod_{\beta'\ne \beta} (X-\beta ) \prod_{\gamma' \ne \gamma} (Y-\gamma ).$$
Because of our disjointness assumption, we can rewrite $N$ as 
$$N = \sum_{\beta \in V_B} \sum_{\gamma \in V_C} \sum_{\x \in V,\, B(\x)=\beta,\, C(\x)=\gamma} A(\x)
  \prod_{\beta'\ne \beta} (X-\beta ) \prod_{\gamma' \ne \gamma} (Y-\gamma ).$$
As before, we deduce that for any $\beta$ in $V_B$ and $\gamma$ in $V_C$, 
$$N(\beta,\gamma)= M_{I,B}'(\beta)\, M_{I,C}'(\gamma) \sum_{\x \in V,\, B(\x)=\beta,\, C(\x)=\gamma} A(\x).$$
Using~\eqref{eq:TrBC}, this implies that 
$$N(\beta,\gamma)= M_{I,B}'(\beta)\, M_{I,C}'(\gamma) \tau_{I,B,C}(A)(\beta,\gamma).$$
Since this holds for all $\beta$ and $\gamma$ roots of respectively
$M_{I,B}$ and $M_{I,C}$, we deduce that
$N=M_{I,B}'\, M_{I,C}'\, \tau_{I,B,C}(A) \bmod \langle M_{I,B},\, M_{I,C}\rangle$.
\end{proof}

As in the previous paragraph, we deduce an algorithm that takes as
input traces of the form $\tau_I(A B^i C^j)$, for some $A,B,C$ in $\L$
and expresses $A$ as a polynomial in $B$ and $C$, if possible.
\begin{algorithm}[H]
  \caption{ConvertFromTrace$(t, M_{I,B}, M_{I,C}, p)$}
  \begin{algorithmic}[1]
    \REQUIRE  $t=(\tau_I(A B^iC^j))_{0 \le i < m, 0 \le i < n}$, $M_{I,B}$ monic in $\F[X]$ of degree $m$,
    $M_{I,C}$ monic in $\F[Y]$ of degree $n$, 
    $p=[\L:\F(B,C)]$
    \ENSURE a polynomial $H$ in $\F[X,Y]_{m,n}$
    \STATE $D =  1/M'_{I,B} \bmod M_{I,B}$
    \STATE $E =  1/M'_{I,C} \bmod M_{I,C}$
    \STATE $N=\rev(M_{I,B}, m+1)\rev(M_{I,C}, n+1)( \sum_{0 \le i <m, 0 \le j < n} t_{i,j} X^iY^i) \bmod \langle X^m, Y^n \rangle$
    \STATE $N^\star = \rev(N, m, n)$
    \STATE $H=\mulmod(N^\star, D E, \langle M_{I,B}, M_{I,C} \rangle)$
    \RETURN $H/p$
  \end{algorithmic}
  \label{algo:tracetopoly2}
\end{algorithm}

\begin{Lemma}
  Suppose that $p=[\L:\F(B,C)]$ is a unit in $\F$. If $A$ is in
  $\F(B,C)$, with $\F(B)$ and $\F(C)$ linearly disjoint,
  Algorithm~\ref{algo:tracetopoly2} computes a polynomial $H$ such
  that $A=H(B,C)$ in time $O(\M(m)\log(m)+\M(n)\log(n)+\M(mn))$, which
  is $O(\M(mn)\log(mn))$.
\end{Lemma}
\begin{proof}
  Correctness follows from the remark that if $A$ is in $\F(B,C)$, say
  $A=H(B,C)$, then $\tau_{I,B,C} (A)=[\L:\F(B,C)]\, H \bmod \langle
  M_{I,B}, M_{I,C} \rangle$.  As to the running time, computing
  the inverses $D$ and $E$ takes total time $O(\M(m)\log(m)+\M(n)\log(n))$;
  the subsequent products take time $O(\M(mn))$.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Algebra embedding and isomorphism} 

Consider two squarefree polynomials $P$ and $Q$ of degrees $m$ and
$n$.  Set $B=k[x]/\ang{P(x)}$, $C=k[y]/\ang{Q(y)}$ and
$A=k[x,y]/\ang{P(x),Q(y)}$. 

\begin{Lemma}
  \label{lemma:compositum}
  Let $(\alpha_i)_{i<m}$ be the roots of $P$ in an algebraic closure
  of$k$, and let $(\beta_i)_{i<n}$ be the roots of $Q$. Assume that
  the elements $\alpha_i\beta_j$ are pairwise distinct. Then $xy$
  generates $A$ as a $k$-algebra.
\end{Lemma}
\begin{proof}
  \todo{Elimination theory should do the job. Sketch: add a variable
    $z=xy$, change order $x>y>z$. Let $R$ be the minpol of $z$, it has
    degree $mn$, hence $k[z]/R$ is isomorphic to $A$ and $z$ generates
    $A$.  The condition in the lemma is also needed to make trace
    formulas work, but is it necessary? Is there a simpler
    formulation?}
\end{proof}

In particular, when $A$, $B$ and $C$ are fields,
Lemma~\ref{lemma:compositum} implies that $A$ is the \emph{compositum} of
$B$ and $C$. When $A$ is a finite field, the condition of the Lemma is
always verified and it implies that $\gcd(m,n)=1$~\cite{todo}. When
$A$ is a number field, it is equivalent to \todo{What?}

Let $R$ be the minimal polynomial of $xy$ in the extension $A/k$, then
we have embeddings of the form
$$\begin{array}{cccc}
\varphi_x: & k[x]/\langle P \rangle & \to & k[z]/\langle R \rangle\\
& x & \mapsto & S
\end{array}$$
and
$$\begin{array}{cccc}
\varphi_y: & k[y]/\langle Q \rangle & \to & k[z]/\langle R \rangle\\
& y & \mapsto & T,
\end{array}$$
for some polynomials $S$ and $T$ in $k[z]$ of degree of the form less
than $mn$ we also have an isomorphism of the form
$$\begin{array}{cccc} 
\Phi:&  k[x,y]/\langle P,Q\rangle & \to & k[z]/\langle R \rangle \\
&  x & \mapsto & S \\
&  y & \mapsto & T \\
&  xy & \mapsfrom & z.
\end{array}$$

In what follows, we discuss algorithms for computing $R$, then
applying $\varphi_x$ and $\varphi_y$ as well as their inverses (when
well-defined), as well as $\Phi$ and its inverse. Except from the
computation of $R$, these are all linear algebra problems. 

If $R,S,T$ are known, then a direct solution is available: modular
composition. For instance assuming $S=\varphi_x(x)$ is known,
$\phi_x(F)$ is computed as $G=F(S) \bmod R$. Using Brent and Kung's
modular composition techniques~\cite{brent+kung}, this can be done in
$O(n m^{(\omega+1)/2})$ operations in $k$, since we evaluate a
polynomial of degree $m$ modulo the polynomial $R$ of degree $mn$ (see
the analysis in~\cite{shoup94}).

We take a different path: we give algorithms whose inputs and outputs
are written on the dual bases of $A$, $B$, $C$ and
$k[z]/\ang{R}$. These are better than the modular composition
approach, and can be combined with the algorithms of
Section~\ref{sec:trace-formulas} to go back to the monomial bases.

In what follows, we write $\tau_P,\tau_Q,\tau_R$ for the traces modulo
the ideals $\langle P\rangle\subset k[x]$, $\langle Q \rangle \subset
k[y]$ and $\langle R \rangle \subset k[z]$. Let as well $I$ be the
ideal $\langle P, Q\rangle$ in $k[x,y]$. To stress the fact that an
element $a\in A$ is represented on the dual basis, we will write
$a^\ast$. When an element, such as $1$, may belong to more than one
algebra, we add a subscript like in $1_P^\ast, 1_R^\ast, \dots$ to
remove ambiguities.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Computing $R$} 

The algorithm for computing $R$ is well-known (see for
instance~\cite{BoFlSaSc06}), and we just recall it here for
completeness. It is based on the following lemma.

\begin{Lemma}
  For $i \ge 0$, $\tau_R(z^i) = \tau_P(x^i) \ \tau_Q(y^i)$.
\end{Lemma}
\begin{proof}
  Because $\Phi$ is an isomorphism, $\tau_R(z^i) = \tau_I(x^i
  y^i)$. Because $A$ is the tensor product of $B$ and
  $C$, $\tau_I(x^iy^i)=\tau_P(x^i) \ \tau_Q(y^i)$.
\end{proof}

We have seen already that the representation of $1$ on the dual basis
of, for example $k[x]/\ang{P}$, contains all the information on the
coefficients of $P$. We will content ourselves with computing
$1_R^\ast$ from the knowledge of $1_P^\ast$ and $1_Q^\ast$. The
coefficients of $R$ can then be recovered as explained in
Section~\ref{sec:trace-formulas}.

\begin{algorithm}[H]
  \caption{ComputeR$(P, Q)$}
  \begin{algorithmic}[1]
    \REQUIRE $1_P^\ast\in k[x]/\ang{P}, 1_Q^\ast\in k[y]/\ang{Q}$
    \ENSURE $1_R^\ast \in k[z]/\ang{R}$
    \STATE $(t_i^\ast) = \rem^t(1_P^\ast,P,mn)$
    \STATE $(u_i^\ast) = \rem^t(1_Q^\ast,Q,mn)$
    \RETURN $(t_i^\ast u_i^\ast)_{0 \le i < mn}$
  \end{algorithmic}
  \label{algo:R}
\end{algorithm}

\begin{Lemma}
  \label{lemma:lift}
  Algorithm~\ref{algo:R} returns $1_R^\ast$ using $O(\M(mn))$ operations in
  $k$.
\end{Lemma}
\begin{proof}
  Correctness is straightforward.  As explained in
  Section~\ref{sec:algor-dual-basis}, computing the traces of the
  powers $x^i$ and $y^i$ takes time $O(\M(mn))$. Then, the last step
  takes $mn$ multiplications in $k$.
\end{proof}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Embedding} 

Next, we show how to compute an embedding, say $\varphi_x$, and its
inverse in quasi-linear time in $mn$. Let thus $a_P$ and $a_R$ be in
respectively $k[x]/\ang{P}$ and $k[z]/\langle R \rangle$, such that
$a_R=\varphi_x(a_P)$. We use the following lemma, which generalizes
the result used to compute $R$.

\begin{Lemma}\label{lemma:traces:PQR}
  Let $a_R=\varphi_x(a_P)$. For $i \ge 0$, $\tau_R(a_Rz^i) =
  \tau_P(a_P x^i) \ \tau_Q(y^i)$ and $\tau_R(a_R S^i) = n\ \tau_P(a_P
  x^i)$.
\end{Lemma}
\begin{proof}
As before: $\tau_R(a_R z^i) = \tau_I(a_R x^i y^i)$ proves the first
equality and $\tau_R(a_R S^i) = \tau_I(a_R x^i)$ proves the second one.
\end{proof}

Given $a_P$, we first show how to compute $a_R$. The algorithm follows
immediately from the lemma. Observe that Algorithm~\ref{algo:R} is a
special case of this one.

\begin{algorithm}[H]
  \caption{Embed$(a,P,R)$}
  \begin{algorithmic}[1]
    \REQUIRE $a_P^\ast\in k[x]/\ang{P}$, $1_Q^\ast\in k[y]/\ang{Q}$
    \ENSURE $a_R^\ast\in k[x]/\ang{R}$ such that $a_R^\ast=\phi_x(a_P^\ast)$
    \STATE $(t_i^\ast) = \rem^t(a_P^\ast,P,mn)$
    \STATE $(u_i^\ast) = \rem^t(1_Q^\ast,Q,mn)$
    \RETURN $(t_i^\ast u_i^\ast)_{0 \le i < mn}$
  \end{algorithmic}
  \label{algo:embed}
\end{algorithm}

The running time analysis of this algorithm is identical to the one in
Lemma~\ref{lemma:lift}.

\begin{Lemma}\label{lemma:algo:embed}
  Algorithm~\ref{algo:embed} correctly computes $\varphi_x(a_P^\ast)$
  using $O(\M(mn))$ operations in $k$.
\end{Lemma}


For the inverse, we take $a_R$ in $k[z]/\langle R \rangle$ of the form
$a_R=\varphi_x(a_P)$, and compute $a_P$. Using the first equality of
Lemma~\ref{lemma:traces:PQR} in the form $\tau_P(a_P x^i) =\tau_R(a_R
z^i)/\tau_Q(y^i)$ would lead to a simple algorithm, but some traces
$\tau_Q(y^i)$ may vanish.\footnote{This leads to an interesting
  problem: after dividing coefficient-wise $a_R^\ast$ by $1_Q^\ast$,
  we are left with a sequence of length $mn$ with some coefficient
  \emph{erased} (those where $\tau_Q(y^i)$ vanishes). Because of the
  hypothesis $a_R=\phi_x(a_P)$, this sequence must be linearly
  recurrent of length $m$ and minimal polynomial $P$. Hence we are
  left with a coding theory problem: recover the \emph{erased}
  coefficients from the known ones.}  Instead, we use the second
equality.

We can see the previous algorithm as a mapping $\phi_x:B^\ast\to
A^\ast$, hence its dual with respect to the bilinear forms $\tau_R$
and $\tau_P$ is a map $\phi_x^t:A\to B$. Let $a_P^\ast,b_P\in B$, and
let $a_R^\ast=\phi_x(a_P^\ast), b_R=\phi_x(b_P)$. Then
\begin{equation}
  n\tau_P(a_P^\ast b_P) = \tau_I(a_R^\ast b_R) = \ang{\phi_x(a_P^\ast),b_R}_R = \ang{a_P^\ast,\phi_x^t(b_R)}_P,
\end{equation}
where the first equality comes from Lemma~\ref{lemma:traces:PQR}, and
we use the fact that the trace is independent from the basis. Hence
$\phi_x^t(b_R)/n = b_P$. So $\phi_x^t/n$ is the inverse of $\phi_x$,
but on the monomial basis. We deduce the following algorithm

\begin{algorithm}[H]
  \caption{InverseEmbed$(a,P,R)$}
  \begin{algorithmic}[1]
    \REQUIRE $a_R\in k[x]/\ang{R}$, $1_Q^\ast\in k[y]/\ang{Q}$
    \ENSURE $a_P\in k[x]/\ang{P}$ such that $a_R=\phi_x(a_P)$
    \STATE $(u_i^\ast) = \rem^t(1_Q^\ast,Q,mn)$
    \STATE $T = \sum_{i=0}^{mn-1} (a_R)_i u_i^\ast x^i$
    \STATE $A = T \bmod P$
    \RETURN $A/n$
  \end{algorithmic}\label{algo:inverseEmbed}
\end{algorithm}

\begin{Lemma}
  Given $a_R$ in the image of $\varphi_x$,
  Algorithm~\ref{algo:inverseEmbed} correctly computes $a_P$ such that
  $a_P=\varphi_x(a_R)$ using $O(\M(mn))$ operations in $k$.
\end{Lemma}
\begin{proof}
  \todo{Correctness.} The cost analysis is identical to the previous
  ones.
\end{proof}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Isomorphism} 

In all that follows, without loss of generality, {\em we assume that
  $m\le n$}. We are not able to give an algorithm for the isomorphism
$\Phi$ that would be as efficient as those for embedding. Instead, we
provide two such algorithms, with different domains of applicability.
In a second time, we discuss computing the inverse of $\Phi$,
for which we use techniques similar to those use for InverseEmbed.

\paragraph{First case: $m$ is small.}
We start by a direct application of the results in the previous
subsection, which is well-suited to situations where $m$ is small compared to $n$. 

Let $F$ be in $\F[X,Y]/\langle P,Q\rangle$ and let
$G=\Phi(F)$. Writing $F=\sum_{0 \le i < m} F_i X^i$, with all $F_i$ in
$\F[Y]/\langle Q \rangle$, we obtain the following straightforward
algorithm to compute $G$: compute all $\varphi_Y(F_i)$, and use a
Horner scheme to deduce $G$ as $G=\sum_{0 \le i < m} \varphi_Y(F_i) S^i$.
\begin{algorithm}[H]
  \caption{ChangeBasis1$(F,P,Q,R)$}
  \begin{algorithmic}[1]
    \STATE $S={\rm Embed}(X,P,R)$
    \STATE $G=0$
    \FOR{$i=m-1,\dots,0$}
    \STATE $G_i = {\rm Embed}(\coeff(F,X,i),Q,R)$
    \STATE $G = GS+G_i \bmod R$
    \ENDFOR
    \RETURN $G$
  \end{algorithmic}
  \label{algo:iso1}
\end{algorithm}

\begin{Lemma}
  Algorithm~\ref{algo:iso1} correctly computes $\Phi(F)$ using
  $O(m\M(mn)\log(mn))$ operations in~$\F$.
\end{Lemma}

The proof is a direct application of Lemma~\ref{lemma:algo:embed}.  As
was the case for $\varphi_X$, we will need the transpose of this
algorithm as well (todo: more explanations)
\begin{algorithm}[H]
  \caption{ChangeBasis1$^t(\gamma,P,Q,R)$}
  \begin{algorithmic}[1]
    \STATE $S={\rm Embed}(X,P,R)$
    \STATE $\ell=0$
    \FOR{$i=0,\dots,m-1$}
    \STATE $\ell_{i,j} = ({\rm Embed}^t(\gamma,Q,R))_j$, {\bf for} $j=0,\dots,n-1$
    \STATE $\gamma = \mulmod^t(\gamma,S,R)$
    \ENDFOR
    \RETURN $\ell$
  \end{algorithmic}
  \label{algo:tiso1}
\end{algorithm}

\paragraph{Second case: $m$ not small.}
The previous algorithm is most efficient when $m$ is small; now, we
propose an alternative solution that does better when $m$ and $n$ are
of the same order of magnitude. 

This approach is based on baby steps / giant steps techniques, as in
Brent and Kung's modular composition algorithm, but uses the fact that
$Z=\Phi(XY)$ to reduce the cost. Given $F$ in $\F[X,Y]/\langle
P,Q\rangle$, let us write
\begin{eqnarray*}
F&=&\sum_{i=0}^{m-1}\sum_{j=0}^{n-1} f_{i,j}X^i Y^j\\
&=&\sum_{i=0}^{m-1}\sum_{j=0}^{n-1} f_{i,j}X^i Y^i Y^{j-i}\\
&=&\sum_{k=-m+1}^{n-1}\sum_{i=0}^{m-1} f_{i,i+k}(XY)^i Y^k\\
&=&\frac{1}{Y^{m-1}} \sum_{k=0}^{m+n-2} H_k(XY) Y^k,
\end{eqnarray*}
with $H_k(Z)=\sum_{0 \le i < m-1} f_{i,i+k-m+1} Z^i$ for all $k$.
This implies that $G=\Phi(F)$ has the form
$$G = \frac{1}{T^{m-1}}\widetilde{G} \mod R\quad\text{with}\quad
\widetilde{G}=\sum_{k=0}^{m+n-2} H_k T^k.$$ We use baby steps / giant
steps techniques from~\cite{LeMeSc13} (inspired by Brent and Kung's
algorithm) to compute $G$, reducing the problem to polynomial matrix
multiplication. Let
$$n'=m+n-1,\quad p=\lceil \sqrt {n'} \rceil,\quad q=\lceil
n'/p\rceil,$$ so that $n \le n' \le 2n-1$ and $p\simeq q \simeq
\sqrt{n}$.  For baby steps, we compute the polynomials $T_i=T^i \bmod
R$, which have degree at most $mn-1$; we write $T_i = \sum_{0 \le j <
  n} T'_{i,j} Z^{jm}$, with $T'_{i,j}$ of degree less than $m$, and
build the polynomial matrix $M_{T'}$ with entries $T'_{i,j}$.  We also
define the matrix $M_H=[H_{iq+j}]_{0 \le i <p, 0 \le j < q}$
containing the polynomials $H_k$ organized in a row-major fashion, and
compute the product $M_V=M_H M_T$. We can then recompose polynomials
from the rows of $M_V$, and conclude with giant steps, using Horner's
scheme to obtain $G$.
\begin{algorithm}[H]
  \caption{ChangeBasis2$(F,P,Q,R)$}
  \begin{algorithmic}[1]
    \STATE $n'=m+n-1$, $p=\lceil \sqrt {n'} \rceil$, $q=\lceil n'/p\rceil$
    \STATE\label{iso2:2} $T={\rm Embed}(Y,Q,R)$
    \STATE\label{iso2:3} $U=1/T \bmod R$
    \STATE\label{iso2:4} $T'=[T^i \bmod R]_{0 \le i < q}$
    \STATE $M_{T'}=[T'_{i,j}]_{0\le i < q, 0, \le j < n}$ \hfill $T'_{i,j}$ as defined above
    \STATE $M_H=[H_{iq+j}]_{0 \le i <p, 0 \le j < q}$ \hfill $H_k$ as defined above
    \STATE\label{iso2:7} $M_V = M_H M_{T'}$
    \STATE $V=[\sum_{0 \le j <n} {M_V}_{i,j} Z^{jm} ]_{0 \le i <p}$
    \STATE $V^\star=[V_i \bmod R]_{0 \le i <p}$
    \STATE $G=0$
    \FOR{$i=p-1,\dots,0$}\label{iso2:11}
    \STATE $G=T^qG+V^\star_i \bmod R$
    \ENDFOR
    \STATE\label{iso2:14} $G=G U^{m-1} \bmod R$
    \RETURN $G$
  \end{algorithmic}
  \label{algo:iso2}
\end{algorithm}

\begin{Lemma}
  Algorithm~\ref{algo:iso2} correctly computes $\Phi(F)$ using
  $O(\M(m) n^{(\omega+1)/2} )$ operations in~$\F$.
\end{Lemma}
\begin{proof}
  Remark first that $n'=O(n)$, and that $p$ and $q$ are both
  $O(\sqrt{n})$. Steps~\ref{iso2:2},~\ref{iso2:3} and~\ref{iso2:14}
  cost $O(\M(mn)\log(mn))$ operations. Steps~\ref{iso2:4} (the baby
  steps) and the loop at Step~\ref{iso2:11} (the giant steps) cost
  $O(\sqrt{n}\M(mn))$. The dominant cost is the matrix product at
  Step~\ref{iso2:7}, which involves matrices of size $O(\sqrt{n})
  \times O(\sqrt{n})$ and $O(\sqrt{n}) \times O(n)$, with polynomial
  entries of degree $m$: this takes $O(\M(m) n^{(\omega+1)/2})$ 
  operations in $\F$.
\end{proof}

As before, we will need the transpose of this algorithm (todo: more
explanations).
\begin{algorithm}[H]
  \caption{ChangeBasis2$^t(\gamma,P,Q,R)$}
  \begin{algorithmic}[1]
    \STATE $n'=m+n-1$, $p=\lceil \sqrt {n'} \rceil$, $q=\lceil n'/p\rceil$
    \STATE $T={\rm Embed}(Y,Q,R)$
    \STATE $U=1/T \bmod R$
    \STATE $T'=[T^i \bmod R]_{0 \le i < q}$
    \STATE $M_{T'}=[T'_{i,j}]_{0\le i < q, 0, \le j < n}$ \hfill $T'_{i,j}$ as defined above
    \STATE $\gamma = \mulmod^t(\gamma, U^{m-1}, R)$
    \STATE $V^\star=[\ ]_{0 \le i < p}$
    \FOR{$i=0,\dots,p-1$}
    \STATE $V^\star_i = \gamma$
    \STATE $\gamma = \mulmod^t(\gamma,T^q,R)$
    \ENDFOR
    \STATE $V = [\rem^t(V^\star_i,R,mn+m-1)]_{0 \le i < p}$
    \STATE $M_V = [(V_{i})_{jm,\dots,jm+2m-1}]_{0 \le i < p, 0 \le j < n}$
    \STATE $M_H = \mul^t(M_V, M_{T'})$
    \STATE $H=[{M_H}_{0,0},\dots,{M_H}_{0,q-1},\dots,{M_H}_{p-1,q-1}]$
    \STATE $\ell=[\coeff(H_{i-j+m-1},i)]_{0 \le i < m, 0 \le j < n}$
    \RETURN $\ell$
  \end{algorithmic}
  \label{algo:tiso2}
\end{algorithm}

\paragraph{Inverse isomorphism.} Finally, as in the previous subsection, we 
give an algorithm for the inverse of $\Phi$, by using the transpose of
$\Phi$. Let $G$ be in $K[Z]/\langle R\rangle$, and let $F$ be such
that $G=\Phi(F)$. In order to compute $F$, we are going to compute the
traces $(\tau_I(F X^i Y^j))_{0 \le i < m, 0 \le i < n}$, since we can
then use them to recover $F$ using the bivariate version of
ConvertFromTrace.

Through the isomorphism $\Phi$, we see that the traces we need are
$(\tau_R(G S^i T^j))_{0 \le i < m, 0 \le i < n}$, which can be
rewritten as $(\ell(S^i T^j))_{0 \le i < m, 0 \le i < n}$, where $\ell
= G \circ \tau_R$. Now, as in the univariate case, the operation $\ell
\mapsto (\ell(S^i T^j))_{0 \le i < m, 0 \le i < n}$ is the dual of the
modular composition $F \in \F[X,Y]/I \mapsto F(S,T) \bmod R$, that is,
the dual of $\Phi$. Thus, given an algorithm ChangeBasis, the inverse
algorithm is as follows:


\begin{algorithm}[H]
  \caption{InverseChangeBasis$(G,P,Q,R)$}
  \begin{algorithmic}[1]
   \STATE $t = {\rm TraceFromMinpoly}(R, mn, 1)$
   \STATE $\ell =\mulmod^t(t, G, R)$
   \STATE $v = {\rm ChangeBasis}^t(\ell, P, Q, R)$
   \RETURN ${\rm ConvertFromTrace}(v, P, Q, 1)$
  \end{algorithmic}
  \label{algo:i_iso1}
\end{algorithm}

The cost of the tranpose algorithm ${\rm ChangeBasis}^t$ is the same
as that of the direct one, up to $O(mn)$. Thus, for both solutions
that we give to compute ChangeBasis, the cost of Step 3 in
Algorithm~\ref{algo:i_iso1} is dominant, so that the inverse algorithm
has the same asymptotic cost as the direct one.

\paragraph{Summary.} For $m \le n$, and neglecting logarithmic factors,
our two solutions for $\Phi$ (or its inverse) have respective costs
$O\tilde{~}(m^2 n)$ and $O\tilde{~}(m n^{(\omega+1)/2})$. Writing
$\delta=mn$, the minimum of the two is
$O\tilde{~}(\delta^{2\omega/(\omega+1)})$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Computing in the algebraic closure of $\F_p$}

Suppose that the following is available:
\begin{itemize}
\item For any prime $\ell$, an $\ell$-adic tower over $\F_p$ is known,
  with in particular polynomials $Q_{\ell^i}$, irreducible of degree
  $\ell^i$ over $\F_p$. In particular, we can identify  $\F_{p^{\ell^i}}$
  with $\F_p[X]/\langle Q_{\ell^i} \rangle$, with $\F_p$-basis
  $U_{\ell^i}=(1,X,\dots,X^{\ell^i-1})$. 

  In addition, for any $i,j$, with $i \le j$, we also have a
  polynomial $Q_{\ell^i,\ell^j}$ in $\F_p[X,Y]$, that defines
  $\F_{p^{\ell^j}}$ over $\F_{p^{\ell^j}}$. This gives us a bivariate
  $\F_p$-basis $B_{\ell^i,\ell^j}=(X^r Y^s)_{0 \le r < \ell^i, 0 \le s
    < \ell^{j-i}}$ of $\F_{p^{\ell^j}}$.
  
  We assume lift-up and push-down are available, that is, conversions
  between the bases $U_{\ell^j}$ and $B_{\ell^i,\ell^j}$.a

\item For any finite extension $\F_q$ of $\F_p$, and any coprime
  $m,n$, we can compute a compositum and do embedding and isomorphism
  in degrees $m,n$ over $\F_q$ (cf. the sections below). For this to
  be feasible, we need a basis for $\F_q$, of course.
\end{itemize}
We want to achieve the following more general versions of embedding
and isomorphism:
\begin{itemize}
\item For any $m \ge 1$, find an irreducible polynomial $Q_m$ of
  degree $m$ in $\F_p[X]$; this will allow us to identify $\F_{p^m}$
  with $\F_p[X]/\langle Q_m \rangle$, with $\F_p$-basis
  $U_m=(1,X,\dots,X^{m-1})$. 

  This is easy: write $m = \ell_1^{c_1} \cdots \ell_s^{c_s}$. Compute
  $Q_{\ell_i^{c_i}}$ for all $i$, and apply the compositum algorithm
  (in a subproduct-tree style) to compute $Q_m$. This also allows us
  to compute the isomorphism $\F_{p^{\ell_1^{c_1}}} \times \cdots
  \times \F_{p^{\ell_s^{c_s}}} \to \F_{p^m}$ and its inverse.

\item Consider $m,m' \ge 1$, with $m'$ a multiple of $m$. Define ${\sf
  Embed}_{m,m'}$ as the conversion from $U_{m}$ to $U_{m'}$. 

  When $g=\gcd(m,m'/m)=1$, we know how to do this in quasi-linear
  time. Otherwise, it is more complicated (to do it right, we would
  need to work over $\F_{p^g}$, but that would require conversion to
  bivariate bases, see below).

  Suppose that $m = \ell_1^{c_1} \cdots \ell_s^{c_s}$ and $m' =
  \ell_1^{e_1} \cdots \ell_s^{e_s}$, with $c_i \le e_i$ for all $i$.
  Take $A$ in $\F_{p^m}$. Decompose it on $\F_{p^{\ell_1^{c_1}}}
  \times \cdots \times \F_{p^{\ell_s^{c_s}}}$ (previous item). Lift-up
  a few times to $\F_{p^{\ell_1^{e_1}}} \times \cdots \times
  \F_{p^{\ell_s^{e_s}}}$. Recompose the result on the basis of
  $\F_{p^{m'}}$ (previous item).

\item For any $m,m' \ge 1$, with $m'$ a multiple of $m$, find a
  polynomial $Q_{m,m'}$ in $\F[X,Y]$ that defines $\F_{p^{m'}}$ over
  $\F_{p^m}$. The associated $\F_p$-basis is $B_{m,m'}=(X^i Y^j)_{0
    \le i < m, 0 \le j < m'/m}$.

  To compute $Q_{m,m'}$, it is enough to handle the case where $m'/m =
  \ell^c$, for some prime $\ell$ (then, we use the same compositum
  process as in the first item). If $\ell$ does not divide $m$, take
  $Q_{m,m'}=Q_{\ell^c}$. Else, we need to work a bit more: let $c'$ be
  the $\ell$-adic valuation of $m$, and consider
  $Q_{\ell^{c'},\ell^c}$. We define $Q_{m,m'}$ as the polynomial
  obtained by applying the embedding $\F_{p^{\ell^{c'}}}\to\F_{p^m}$ to
  all coefficients of $Q_{\ell^{c'},\ell^c}$.
  
\item Consider $m,m' \ge 1$, with $m'$ a multiple of $m$. Define ${\sf
  ChangeBasis}_{m,m'}$ as the conversion from $U_{m'}$ to $B_{m,m'}$.
  
  Suppose that $m = \ell_1^{c_1} \cdots \ell_s^{c_s}$ and $m' =
  \ell_1^{e_1} \cdots \ell_s^{e_s}$, with $c_i \le e_i$ for all $i$.
  Take $A$ written on $U_{m'}$. Decompose it on $\F_{p^{\ell_1^{e_1}}}
  \times \cdots \times \F_{p^{\ell_s^{e_s}}}$. Apply $\ell_i$-adic
  change-of basis, to rewrite $A$ on the products of the bases
  $B_{\ell_1^{c_1},\ell_1^{e_1}},\dots,B_{\ell_s^{c_s},\ell_s^{e_s}}$.
  Now work with the components of degrees $\ell_1^{c_1},\dots,\ell_s^{c_s}$,
  to rewrite $A$ univariate in $X$ (for $\F_{p^m}$), multivariate 
  in $Y_1,\dots,Y_s$. Finish as in the first item (but with coefficients in
  $\F_{p^m}$).
\end{itemize}

With this, we can do $+,\times$ over the algebraic closure (embed the
operands in a common extension), relative characteristic and minimal
polynomials (and thus traces and norms), and probably most other
required operations.




\bibliographystyle{plain} \bibliography{defeo}

\end{document}




% Local Variables:
% mode:flyspell
% ispell-local-dictionary:"american"
% mode:TeX-PDF
% mode:reftex
% End:
